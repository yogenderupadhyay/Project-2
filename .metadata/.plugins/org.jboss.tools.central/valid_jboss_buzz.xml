<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Performance baseline for jBPM 7 (7.8.0)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/7SJXLb431B4/performance-baseline-for-jbpm-7-780.html" /><category term="feed_group_name_jbossjbpmcommunity" scheme="searchisko:content:tags" /><category term="feed_name_swiderskimaciej" scheme="searchisko:content:tags" /><category term="jBPM" scheme="searchisko:content:tags" /><category term="jbpm_7" scheme="searchisko:content:tags" /><category term="jbpm_baseline" scheme="searchisko:content:tags" /><category term="jbpm_benchmark" scheme="searchisko:content:tags" /><category term="jbpm_performance" scheme="searchisko:content:tags" /><category term="kie_server_performance" scheme="searchisko:content:tags" /><category term="performance" scheme="searchisko:content:tags" /><author><name>Maciej Swiderski</name></author><id>searchisko:content:id:jbossorg_blog-performance_baseline_for_jbpm_7_7_8_0</id><updated>2018-07-18T01:51:28Z</updated><published>2018-07-18T01:51:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;The aim of this article is to show a base information about performance of the jBPM to set a baseline and to answer basic question how good jBPM performs when it comes to execution. This is not to be seen as competitive information or show jBPM is faster or slower than other engines but more for setting a stage and open the door for more performance tests that can be performed in different types of environments.&lt;br /&gt;&lt;br /&gt;&lt;h2 style="text-align: left;"&gt;Overview&lt;/h2&gt;&lt;div&gt;The performance test is executed on KIE Server so it actually measures performance of the jBPM as a running service instead of focusing on raw execution of the APIs. So anyone can perform this tests by following the instructions at the end of this article.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2 style="text-align: left;"&gt;Environment&lt;/h2&gt;&lt;div&gt;The test has been executed on:&lt;/div&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;community 7.8.0 single zip distribution that you can download on &lt;a href="http://jbpm.org/"&gt;jbpm.org&lt;/a&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;WildFly 11&lt;/li&gt;&lt;li&gt;Postgres data base&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;hardware&lt;/li&gt;&lt;ul&gt;&lt;li&gt;macOS 10.13.4&lt;/li&gt;&lt;li&gt;Processor Intel Core i7 2,3 GHz&lt;/li&gt;&lt;li&gt;Memory 16GB&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;JMeter as the test client&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;All components (client, application server and database) are on the same hardware, meaning they share the resources.&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2 style="text-align: left;"&gt;Scenarios&lt;/h2&gt;&lt;div&gt;There are three scenarios selected for this test that are executed with various concurrency settings.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3 style="text-align: left;"&gt;Script task&lt;/h3&gt;&lt;div style="text-align: left;"&gt;Most basic process definition that runs directly from the beginning till the end without persisting any state in between.&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-ya0BU3L9lig/W03JnXUZRSI/AAAAAAAABfI/6RklHuiiFsIWBS_i5DFSewXs69B1ajjGgCEwYBhgL/s1600/Screen%2BShot%2B2018-07-17%2Bat%2B18.46.03.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="460" data-original-width="1118" height="262" src="https://2.bp.blogspot.com/-ya0BU3L9lig/W03JnXUZRSI/AAAAAAAABfI/6RklHuiiFsIWBS_i5DFSewXs69B1ajjGgCEwYBhgL/s640/Screen%2BShot%2B2018-07-17%2Bat%2B18.46.03.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;This test consists of just single call to KIE Server.&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3 style="text-align: left;"&gt;User task&lt;/h3&gt;&lt;div style="text-align: left;"&gt;User task based process that will persist its state when reaching user task activity. Completion of the task is done in another call.&amp;nbsp;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-N416TovvgdQ/W03JnhrhINI/AAAAAAAABfM/lE5zWmONaV4kSe5Z_k4XStuBn6ySb7OagCLcBGAs/s1600/Screen%2BShot%2B2018-07-17%2Bat%2B18.46.16.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="440" data-original-width="1146" height="244" src="https://2.bp.blogspot.com/-N416TovvgdQ/W03JnhrhINI/AAAAAAAABfM/lE5zWmONaV4kSe5Z_k4XStuBn6ySb7OagCLcBGAs/s640/Screen%2BShot%2B2018-07-17%2Bat%2B18.46.16.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;This test consists of three calls to KIE Server&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;start process&lt;/li&gt;&lt;li&gt;get tasks for given process instance&lt;/li&gt;&lt;li&gt;complete first task&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3 style="text-align: left;"&gt;Parallel script and user tasks&lt;/h3&gt;&lt;div style="text-align: left;"&gt;More advanced process definition that combines both user and script tasks with parallel gateways.&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-yhTJqTRszrc/W03JXGEwGTI/AAAAAAAABfA/lFLD5yt_Q7EfjNq3fg9r8YiE56ttetuEQCLcBGAs/s1600/Screen%2BShot%2B2018-07-17%2Bat%2B18.44.28.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="637" data-original-width="1600" height="252" src="https://2.bp.blogspot.com/-yhTJqTRszrc/W03JXGEwGTI/AAAAAAAABfA/lFLD5yt_Q7EfjNq3fg9r8YiE56ttetuEQCLcBGAs/s640/Screen%2BShot%2B2018-07-17%2Bat%2B18.44.28.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;div&gt;This test consists of five calls to KIE Server&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;start process&lt;/li&gt;&lt;li&gt;get tasks for given process instance&lt;/li&gt;&lt;li&gt;complete first task&lt;/li&gt;&lt;li&gt;get tasks for given process instance&lt;/li&gt;&lt;li&gt;complete second task&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2 style="text-align: left;"&gt;Performance test&lt;/h2&gt;&lt;div style="text-align: left;"&gt;Tests are separated per scenario and then number of concurrent threads. The test is designed to run fixed number of process instances (&lt;b&gt;1000&lt;/b&gt;) in the shortest possible time.&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3 style="text-align: left;"&gt;Script task execution results&lt;/h3&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-O93nreW2x-8/W03S-wmq_sI/AAAAAAAABfc/cN7HNMkJPfEfnNYuytaCUe0Ug0v984eTgCLcBGAs/s1600/Screen%2BShot%2B2018-07-13%2Bat%2B13.54.07.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="373" data-original-width="1168" height="204" src="https://3.bp.blogspot.com/-O93nreW2x-8/W03S-wmq_sI/AAAAAAAABfc/cN7HNMkJPfEfnNYuytaCUe0Ug0v984eTgCLcBGAs/s640/Screen%2BShot%2B2018-07-13%2Bat%2B13.54.07.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Actual figures&lt;/div&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;1 thread -&amp;nbsp;11 421 ms&lt;/li&gt;&lt;li&gt;4 threads -&amp;nbsp;4 428 ms&lt;/li&gt;&lt;li&gt;8 threads -&amp;nbsp;3 124 ms&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Throughput:&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;1 thread -&amp;nbsp;91 instances/s&lt;/li&gt;&lt;li&gt;4 threads -&amp;nbsp;240 instances/s&lt;/li&gt;&lt;li&gt;8 threads -&amp;nbsp;361 instances/s&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;h3 style="text-align: left;"&gt;User task execution results&lt;/h3&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-f0u-rD6-gRA/W03TMGT4ZuI/AAAAAAAABfk/-4Afd8j-yN85HMVUA0Ey2wOHYeOaOnkXACLcBGAs/s1600/Screen%2BShot%2B2018-07-13%2Bat%2B13.20.13.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="379" data-original-width="1166" height="208" src="https://2.bp.blogspot.com/-f0u-rD6-gRA/W03TMGT4ZuI/AAAAAAAABfk/-4Afd8j-yN85HMVUA0Ey2wOHYeOaOnkXACLcBGAs/s640/Screen%2BShot%2B2018-07-13%2Bat%2B13.20.13.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;div&gt;Actual figures&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;1 thread -&amp;nbsp;64 439 ms&lt;/li&gt;&lt;li&gt;4 threads -&amp;nbsp;18 397 ms&lt;/li&gt;&lt;li&gt;8 threads -&amp;nbsp;13 927 ms&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Throughput:&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;1 thread -&amp;nbsp;16 instances/s&lt;/li&gt;&lt;li&gt;4 threads -&amp;nbsp;52 instances/s&lt;/li&gt;&lt;li&gt;8 threads -&amp;nbsp;72 instances/s&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;b&gt;NOTE: throughput is for complete process instance execution including completion of user task&lt;/b&gt;&lt;/div&gt;&lt;h3 style="text-align: left;"&gt;&lt;br /&gt;&lt;/h3&gt;&lt;h3 style="text-align: left;"&gt;Parallel script and user tasks execution results&lt;/h3&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-vePybn1Tw6s/W03TMMS9FqI/AAAAAAAABfg/BLzjExfYKaE71p-4SVfuBdGcyyhBIW3OQCEwYBhgL/s1600/Screen%2BShot%2B2018-07-13%2Bat%2B13.45.18.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="378" data-original-width="1171" height="206" src="https://2.bp.blogspot.com/-vePybn1Tw6s/W03TMMS9FqI/AAAAAAAABfg/BLzjExfYKaE71p-4SVfuBdGcyyhBIW3OQCEwYBhgL/s640/Screen%2BShot%2B2018-07-13%2Bat%2B13.45.18.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;div&gt;Actual figures&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;1 thread -&amp;nbsp;153 543 ms&lt;/li&gt;&lt;li&gt;4 threads -&amp;nbsp;34 769 ms&lt;/li&gt;&lt;li&gt;8 threads -&amp;nbsp;20 426 ms&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Throughput:&amp;nbsp;&lt;/div&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;ul&gt;&lt;li&gt;1 thread -&amp;nbsp;11 instances/s&lt;/li&gt;&lt;li&gt;4 threads -&amp;nbsp;45 instances/s&lt;/li&gt;&lt;li&gt;8 threads -&amp;nbsp;70 instances/s&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;NOTE: throughput is for complete process instance execution including completion of user tasks&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;/div&gt;&lt;h2 style="text-align: left;"&gt;Conclusion&lt;/h2&gt;&lt;div style="text-align: left;"&gt;These performance results show the base performance of the jBPM execution through KIE Server - meaning it adds network and marshalling overhead. The application server or hardware has not been tuned in anyway and the sample processes are simple as well. So with that said, it's not meant to provide complete performance report but rather a base line. More advanced performance tests can be performed on dedicated hardware and with tuned application server and database for optimal performance.&lt;/div&gt;&lt;h2 style="text-align: left;"&gt;&lt;br /&gt;&lt;/h2&gt;&lt;h2 style="text-align: left;"&gt;Instruction for execution&lt;/h2&gt;&lt;div style="text-align: left;"&gt;In case someone would like to try these tests themselves, here are few steps one how to do it.&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;ol style="text-align: left;"&gt;&lt;li&gt;Download and install jBPM 7.8.0 (or newer)&lt;/li&gt;&lt;ol&gt;&lt;li&gt;&lt;a href="http://www.jbpm.org/download/download.html"&gt;download&lt;/a&gt;&amp;nbsp;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.jbpm.org/learn/gettingStarted.html"&gt;getting started&lt;/a&gt;&amp;nbsp;&lt;/li&gt;&lt;/ol&gt;&lt;li&gt;Change data base to PostgreSQL or MySQL - see &lt;a href="http://www.jbpm.org/learn/gettingStarted.html"&gt;getting started&lt;/a&gt; (bottom of the page)&lt;/li&gt;&lt;li&gt;Import &lt;a href="https://github.com/mswiderski/performance-samples"&gt;this project&lt;/a&gt; into workbench on your running jBPM server&lt;/li&gt;&lt;li&gt;Download and start JMeter&lt;/li&gt;&lt;li&gt;Open &lt;a href="https://github.com/mswiderski/performance-samples/blob/master/kie-server-performance.jmx"&gt;this script&lt;/a&gt; in JMeter&lt;/li&gt;&lt;li&gt;Run the selected scenario.&lt;/li&gt;&lt;/ol&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/7SJXLb431B4" height="1" width="1" alt=""/&gt;</content><summary>The aim of this article is to show a base information about performance of the jBPM to set a baseline and to answer basic question how good jBPM performs when it comes to execution. This is not to be seen as competitive information or show jBPM is faster or slower than other engines but more for setting a stage and open the door for more performance tests that can be performed in different types o...</summary><dc:creator>Maciej Swiderski</dc:creator><dc:date>2018-07-18T01:51:00Z</dc:date><feedburner:origLink>http://mswiderski.blogspot.com/2018/07/performance-baseline-for-jbpm-7-780.html</feedburner:origLink></entry><entry><title>How to call the OpenShift REST API from C#</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/oVuI5X-AeRM/" /><category term=".NET Core" /><category term="C#" /><category term="Red Hat OpenShift Container Platform" /><category term=".NET" /><category term=".NET Framework" /><category term="c++" /><category term="kubernetes" /><category term="OpenShift REST API" /><category term="Red Hat OpenShift" /><category term="Swagger" /><category term="Visual Studio" /><author><name>Takayoshi Tanaka</name></author><id>https://developers.redhat.com/blog/?p=506917</id><updated>2018-07-17T19:03:20Z</updated><published>2018-07-17T19:03:20Z</published><content type="html">&lt;p&gt;When you want to do automated tasks for builds and deployments with Red Hat OpenShift, you might want to take advantage of the &lt;a href="https://docs.openshift.com/container-platform/3.9/rest_api/index.html" target="_blank" rel="noopener"&gt;OpenShift REST API&lt;/a&gt;. In scripts you can use &lt;code&gt;oc&lt;/code&gt; CLI command which talks to the REST APIs. However there are times when it is more convenient to do this directly from your C# code without having to invoke an external program. This is the value of having an infrastructure platform that is exposed as services with an open API.&lt;/p&gt; &lt;p&gt;If you want to call the API from your C# code, you have to create a request object, call the API, and parse the response object. The upstream project, OpenShift Origin, provides &lt;a href="https://github.com/openshift/origin/blob/master/api/swagger-spec/openshift-openapi-spec.json" target="_blank" rel="noopener"&gt;a Swagger 2.0 specification&lt;/a&gt; and you can generate a client library for each programming language. Of course, C# is supported.  This isn&amp;#8217;t a new approach, Kubernetes has &lt;a href="https://github.com/kubernetes-client/csharp" target="_blank" rel="noopener"&gt;a repository&lt;/a&gt; that is generated by Swagger Codegen.&lt;/p&gt; &lt;p&gt;For C#, we can use Microsoft Visual Studio to generate a C# client library for a REST API. In this article, I&amp;#8217;ll walk you through the process of generating the library from the definition.&lt;br /&gt; &lt;span id="more-506917"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Visual Studio can accept the Swagger 2.0 definition directly, but the OpenShift Swagger 2.0 API definition has some issues generating a C# library. However, with Kubernetes, some conversions are defined ussing JSONPath, see the &lt;a href="https://github.com/kubernetes-client/gen/blob/master/openapi/csharp.xml#L45-L50" target="_blank" rel="noopener"&gt;GitHub repo&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Following these conversions, I wrote &lt;a href="https://github.com/tanaka-takayoshi/OpenShift-CSharp-SDK/blob/3.9.0-sdk-rc1/OpenShift.OpenAPITransform/Program.cs" target="_blank" rel="noopener"&gt;some C# code&lt;/a&gt; to apply the required conversions to the original definition. If you want to generate code for your own project, please feel free to use my project to convert a definition file. Then you can generate C# code from the generated definition file.&lt;/p&gt; &lt;p&gt;Now, prepare the placeholder project in Visual Studio. The project framework should be .NET Framework instead of .NET Core. It seems this is just a limit of the tooling. You can create a .NET Core (&lt;code&gt;netstandard&lt;/code&gt; or &lt;code&gt;netcoreapp&lt;/code&gt;) client library later. After creating a .NET Framework project, right-click the&lt;strong&gt; REST API Client&lt;/strong&gt; context menu in the project and select &lt;strong&gt;Add&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-medium wp-image-507017 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/07/image01.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/07/image01-300x221.png" alt="" width="300" height="221" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/07/image01-300x221.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/07/image01-768x565.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/07/image01.png 967w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/p&gt; &lt;p&gt;Then specify the file path for the generated definition file.&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-medium wp-image-507027 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/07/image02-1024x359.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/07/image02-300x105.png" alt="" width="300" height="105" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/07/image02-300x105.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/07/image02-768x269.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/07/image02-1024x359.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/07/image02.png 1050w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/p&gt; &lt;p&gt;If you want to use the client library with .NET Core, please create a placeholder project. I&amp;#8217;m using a .NET Core class library project. Then, modify the &lt;code&gt;csproj&lt;/code&gt; file, as follows, to add a package reference for &lt;code&gt;Microsoft.Rest.ClientRuntime&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt;&amp;#60;Project Sdk="Microsoft.NET.Sdk"&amp;#62; &amp;#60;PropertyGroup&amp;#62; &amp;#60;TargetFrameworks&amp;#62;netstandard2.0&amp;#60;/TargetFrameworks&amp;#62; &amp;#60;/PropertyGroup&amp;#62; &amp;#60;ItemGroup&amp;#62; &amp;#60;PackageReference Include="Microsoft.Rest.ClientRuntime" Version="2.3.11" /&amp;#62; &amp;#60;/ItemGroup&amp;#62; &amp;#60;/Project&amp;#62; &lt;/pre&gt; &lt;p&gt;Then just simply copy and paste the folder including the generated code.&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-medium wp-image-507047 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/07/image03.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/07/image03-300x102.png" alt="" width="300" height="102" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/07/image03-300x102.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/07/image03.png 388w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/p&gt; &lt;p&gt;I publish the &lt;a href="https://www.nuget.org/packages/OpenShift.Service.Core/3.9.0-sdk-rc1"&gt;NuGet package&lt;/a&gt; for this generated project. Since the project is not listed in the search results, please specify the full name &lt;code&gt;OpenShift.Service.Core&lt;/code&gt; to add the package reference into your own C# project. You also have to add the &lt;code&gt;Microsoft.Rest.ClientRuntime&lt;/code&gt; package reference.&lt;/p&gt; &lt;p&gt;Now you can write C# code to call the OpenShift REST API. Here is a simple example to call a GET pod REST API.&lt;/p&gt; &lt;pre&gt;//if your master URL has an invalid SSL, please add a custom validation callback. var handler = new HttpClientHandler { ServerCertificateCustomValidationCallback = HttpClientHandler.DangerousAcceptAnyServerCertificateValidator }; //replace the acutual OpenShift master host name and your token to log in. var client = new OpenShiftAPIwithKubernetes(new Uri("https://:8443/"), new TokenCredentials(""), handler); var pods = await client.ListCoreV1NamespacedPodAsync(""); foreach (var pod in pods.Items) { Console.WriteLine(pod.Metadata.Name + "=" + pod.Status.Phase); } &lt;/pre&gt; &lt;p&gt;To get a token for test purposes, log in to the OpenShift web console and select &lt;strong&gt;Copy Login Command&lt;/strong&gt; from the context menu in the upper right corner (to the right of the user icon).&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-medium wp-image-507117 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/07/image04.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/07/image04-300x105.png" alt="" width="300" height="105" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/07/image04-300x105.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/07/image04.png 474w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/p&gt; &lt;p&gt;The pasted command has the following format. Use the &lt;code&gt;master_host&lt;/code&gt; value and token value. Note that this token will expire. We recommend using &lt;a href="https://docs.openshift.com/container-platform/3.9/dev_guide/service_accounts.html" target="_blank" rel="noopener"&gt;service accounts&lt;/a&gt; for production purposes.&lt;/p&gt; &lt;pre&gt;oc login https://&amp;#60;master_host&amp;#62;:8443 --token=&amp;#60;token&amp;#62; &lt;/pre&gt; &lt;p&gt;Enjoy writing code to work with the OpenShift REST API. If you find any issues, please send feedback to &lt;a href="https://github.com/tanaka-takayoshi/OpenShift-CSharp-SDK/tree/master"&gt;my repository&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F17%2Fcalling-the-openshift-rest-api-from-your-c-code%2F&amp;#38;linkname=How%20to%20call%20the%20OpenShift%20REST%20API%20from%20C%23" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F17%2Fcalling-the-openshift-rest-api-from-your-c-code%2F&amp;#38;linkname=How%20to%20call%20the%20OpenShift%20REST%20API%20from%20C%23" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F17%2Fcalling-the-openshift-rest-api-from-your-c-code%2F&amp;#38;linkname=How%20to%20call%20the%20OpenShift%20REST%20API%20from%20C%23" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F17%2Fcalling-the-openshift-rest-api-from-your-c-code%2F&amp;#38;linkname=How%20to%20call%20the%20OpenShift%20REST%20API%20from%20C%23" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F17%2Fcalling-the-openshift-rest-api-from-your-c-code%2F&amp;#38;linkname=How%20to%20call%20the%20OpenShift%20REST%20API%20from%20C%23" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F17%2Fcalling-the-openshift-rest-api-from-your-c-code%2F&amp;#38;linkname=How%20to%20call%20the%20OpenShift%20REST%20API%20from%20C%23" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F17%2Fcalling-the-openshift-rest-api-from-your-c-code%2F&amp;#38;linkname=How%20to%20call%20the%20OpenShift%20REST%20API%20from%20C%23" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F17%2Fcalling-the-openshift-rest-api-from-your-c-code%2F&amp;#38;linkname=How%20to%20call%20the%20OpenShift%20REST%20API%20from%20C%23" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F17%2Fcalling-the-openshift-rest-api-from-your-c-code%2F&amp;#38;title=How%20to%20call%20the%20OpenShift%20REST%20API%20from%20C%23" data-a2a-url="https://developers.redhat.com/blog/2018/07/17/calling-the-openshift-rest-api-from-your-c-code/" data-a2a-title="How to call the OpenShift REST API from C#"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/07/17/calling-the-openshift-rest-api-from-your-c-code/"&gt;How to call the OpenShift REST API from C#&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/oVuI5X-AeRM" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;When you want to do automated tasks for builds and deployments with Red Hat OpenShift, you might want to take advantage of the OpenShift REST API. In scripts you can use oc CLI command which talks to the REST APIs. However there are times when it is more convenient to do this directly from your C# code [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/07/17/calling-the-openshift-rest-api-from-your-c-code/"&gt;How to call the OpenShift REST API from C#&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/07/17/calling-the-openshift-rest-api-from-your-c-code/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">506917</post-id><dc:creator>Takayoshi Tanaka</dc:creator><dc:date>2018-07-17T19:03:20Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/07/17/calling-the-openshift-rest-api-from-your-c-code/</feedburner:origLink></entry><entry><title>JBoss Tools and Red Hat Developer Studio for Eclipse Photon</title><link rel="alternate" type="text/html" href="http://feedproxy.google.com/~r/jbossbuzz/~3/bzeusGCgaZA/12.0.0.ga-for-photon.html" /><category term="release" /><category term="jbosstools" /><category term="devstudio" /><category term="jbosscentral" /><author><name>jeffmaury</name></author><id>https://tools.jboss.org/blog/12.0.0.ga-for-photon.html</id><updated>2018-07-17T15:43:40Z</updated><published>2018-07-17T00:00:00Z</published><content type="html">&lt;div&gt;&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;&lt;a href="https://tools.jboss.org/downloads/jbosstools/photon/4.6.0.Final.html"&gt;JBoss Tools 4.6.0&lt;/a&gt; and &lt;a href="https://tools.jboss.org/downloads/devstudio/photon/12.0.0.GA.html"&gt;Red Hat Developer Studio 12.0&lt;/a&gt; for Eclipse Photon are here waiting for you. Check it out!&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/blog/images/devstudio12.png" alt="devstudio12" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="installation"&gt;&lt;a class="anchor" href="#installation"&gt;&lt;/a&gt;Installation&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Red Hat Developer Studio comes with everything pre-bundled in its installer. Simply download it from our &lt;a href="https://developers.redhat.com/products/devstudio/overview/"&gt;Red Hat Developer product page&lt;/a&gt; and run it like this:&lt;/p&gt; &lt;/div&gt; &lt;div class="literalblock"&gt; &lt;div class="content"&gt; &lt;pre&gt;java -jar devstudio-&amp;lt;installername&amp;gt;.jar&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;JBoss Tools or Bring-Your-Own-Eclipse (BYOE) Developer Studio require a bit more:&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;This release requires at least Eclipse 4.8 (Photon) but we recommend using the latest &lt;a href="http://www.eclipse.org/downloads/packages/eclipse-ide-java-ee-developers/photonr"&gt;Eclipse 4.8 Photon JEE Bundle&lt;/a&gt; since then you get most of the dependencies preinstalled.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Once you have installed Eclipse, you can either find us on the Eclipse Marketplace under &amp;quot;JBoss Tools&amp;quot; or &amp;quot;Red Hat Developer Studio&amp;quot;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;For JBoss Tools, you can also use our update site directly.&lt;/p&gt; &lt;/div&gt; &lt;div class="literalblock"&gt; &lt;div class="content"&gt; &lt;pre&gt;http://download.jboss.org/jbosstools/photon/stable/updates/&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="what-is-new"&gt;&lt;a class="anchor" href="#what-is-new"&gt;&lt;/a&gt;What is new?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Our main focus for this release was on adoption of Java10, improvements for container based development and bug fixing. Eclipse Photon itself has &lt;a href="https://www.youtube.com/watch?v=gDAb_iyO5Fc&amp;amp;list=PLy7t4z5SYNaQjVGIS9YUfZzFQpNFYpCny"&gt;a lot of new cool stuff&lt;/a&gt; but let me highlight just a few updates in both Eclipse Photon and JBoss Tools plugins that I think are worth mentioning.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="openshift-3"&gt;&lt;a class="anchor" href="#openshift-3"&gt;&lt;/a&gt;OpenShift 3&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="enhanced-spring-boot-support-for-server-adapter"&gt;&lt;a class="anchor" href="#enhanced-spring-boot-support-for-server-adapter"&gt;&lt;/a&gt;Enhanced Spring Boot support for server adapter&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Spring Boot runtime was already supported by the OpenShift server adapter. However, it has one major limitation: files and resources were synchronized between the local workstation and the remote pod(s) only for the main project. If your Spring Boot application had dependencies that were present in the local workspace, any change to a file or resource of one of these dependencies was not handled. This is not true anymore.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="server-tools"&gt;&lt;a class="anchor" href="#server-tools"&gt;&lt;/a&gt;Server tools&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="wildfly-13-server-adapter"&gt;&lt;a class="anchor" href="#wildfly-13-server-adapter"&gt;&lt;/a&gt;Wildfly 13 Server Adapter&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;A server adapter has been added to work with Wildfly 13. It adds support for Servlet 4.0.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="fuse-tooling"&gt;&lt;a class="anchor" href="#fuse-tooling"&gt;&lt;/a&gt;Fuse Tooling&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="camel-rest-dsl-from-wsdl-wizard"&gt;&lt;a class="anchor" href="#camel-rest-dsl-from-wsdl-wizard"&gt;&lt;/a&gt;Camel Rest DSL from WSDL wizard&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;There is a new &lt;em&gt;&amp;quot;Camel Rest DSL from WSDL&amp;quot;&lt;/em&gt; wizard. This wizard wraps the &lt;a href="https://github.com/jboss-fuse/wsdl2rest"&gt;wsdl2rest tool&lt;/a&gt; now included with the Fuse 7 distribution, which takes a WSDL file for a SOAP-based (JAX-WS) web service and generates a combination of CXF-generated code and a Camel REST DSL route to make it accessible using REST operations.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;To start, you need an existing Fuse Integration project in your workspace and access to the WSDL for the SOAP service. Then use &lt;em&gt;File→New→Other…​&lt;/em&gt; and select &lt;em&gt;Red Hat Fuse→Camel Rest DSL from WSDL&lt;/em&gt; wizard.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;On the first page of the wizard, select your WSDL and the Fuse Integration project in which to generate the Java code and Camel configuration.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/fusetools/images/wsdl2rest-wizard-page-one.jpg" alt="SOAP to REST Wizard page 1" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;On the second page, you can customize the Java folder path for your generated classes, the folder for the generated Camel file, plus any customization for the SOAP service address and destination REST service address.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/fusetools/images/wsdl2rest-wizard-page-two.jpg" alt="SOAP to REST Wizard page 2" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Click &lt;em&gt;Finish&lt;/em&gt; and the new Camel configuration and associated Java code are generated in your project. The wizard determines whether your project is Blueprint, Spring, or Spring Boot based, and it creates the corresponding artifacts without requiring any additional input. When the wizard is finished, you can open your new Camel file in the Fuse Tooling Route Editor to view what it created.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/fusetools/images/fuse-editor-rest-tab-no-properties.jpg" alt="Fuse Tooling editor Rest Tab" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;That brings us to another new functionality, the REST tab in the Fuse Tooling Route Editor.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect3"&gt; &lt;h4 id="camel-editor-rest-tab"&gt;&lt;a class="anchor" href="#camel-editor-rest-tab"&gt;&lt;/a&gt;Camel Editor REST tab&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Fuse Tooling Route Editor provides a new &lt;em&gt;REST&lt;/em&gt; tab. For this release, the contents of this tab is read-only and includes the following information:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Details for the REST Configuration element including the component (jetty, netty, servlet, etc.), the context path, the port, binding mode (JSON, XML, etc.), and host. There is only one REST Configuration element.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;A list of REST elements that collect REST operations. A configuration can have more than one REST element. Each REST element has an associated property page that displays additional details such as the path and the data it consumes or produces.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/fusetools/images/fuse-editor-rest-tab-rest-element-properties.jpg" alt="Fuse Tooling Rest Elements Properties View" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;A list of REST operations for the selected REST element. Each of the operations has an associated property page that provides details such as the URI and output type.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/fusetools/images/fuse-editor-rest-tab-rest-operation-properties.jpg" alt="Fuse Tooling Rest Operations Properties View" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;For this release, the REST tab is read-only. If you want to edit the REST DSL, use the Route Editor Source tab. When you make changes and save them in the Source tab, the REST tab refreshes to show your updates.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect3"&gt; &lt;h4 id="camel-uri-completion-with-xml-dsl"&gt;&lt;a class="anchor" href="#camel-uri-completion-with-xml-dsl"&gt;&lt;/a&gt;Camel URI completion with XML DSL&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;As announced &lt;a href="https://developers.redhat.com/blog/2018/01/31/apache-camel-uri-completion-eclipse-xml-editor/"&gt;here&lt;/a&gt;, it was already possible to have Camel URI completion with XML DSL in the source tab of the Camel Route editor by installing the &lt;a href="https://github.com/camel-tooling/camel-lsp-client-eclipse"&gt;Language Support for Apache Camel&lt;/a&gt; in your IDE.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;This feature is now installed by default with Fuse Tooling!&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/fusetools/images/completionSourceEditor.gif" alt="Camel URI completion in source tab of Camel Editor" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="maven"&gt;&lt;a class="anchor" href="#maven"&gt;&lt;/a&gt;Maven&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="maven-support-updated-to-m2e-1-9-1"&gt;&lt;a class="anchor" href="#maven-support-updated-to-m2e-1-9-1"&gt;&lt;/a&gt;Maven support updated to M2E 1.9.1&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Maven support is based on Eclipse M2E 1.9.1, bringing the following features:&lt;/p&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="advanced-classpath-isolation"&gt;&lt;a class="anchor" href="#advanced-classpath-isolation"&gt;&lt;/a&gt;Advanced classpath isolation&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Thanks to Eclipse Photon, there are new two different classpathes, the main and the test classpath. The main classes will now no longer see the test classes and dependencies&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="embedded-maven-runtime"&gt;&lt;a class="anchor" href="#embedded-maven-runtime"&gt;&lt;/a&gt;Embedded Maven runtime&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The embedded Maven runtime is now based on Apache Maven 3.5.3.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="archetype-catalog-management"&gt;&lt;a class="anchor" href="#archetype-catalog-management"&gt;&lt;/a&gt;Archetype catalog management&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;It is now possible to disable an archetype catalog.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="java-9-10-support"&gt;&lt;a class="anchor" href="#java-9-10-support"&gt;&lt;/a&gt;Java 9/10 support&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Support for Java 9/10 has been improved: bugs fixes, better handling of module path.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="java-developement-tools-jdt"&gt;&lt;a class="anchor" href="#java-developement-tools-jdt"&gt;&lt;/a&gt;Java Developement Tools (JDT)&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="support-for-java-10"&gt;&lt;a class="anchor" href="#support-for-java-10"&gt;&lt;/a&gt;Support for Java™ 10&lt;/h4&gt; &lt;div class="sect4"&gt; &lt;h5 id="quick-fix-to-change-project-compliance-and-jre-to-10"&gt;&lt;a class="anchor" href="#quick-fix-to-change-project-compliance-and-jre-to-10"&gt;&lt;/a&gt;Quick fix to change project compliance and JRE to 10&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;A quick fix &lt;strong&gt;Change project compliance and JRE to 10&lt;/strong&gt; is provided to quickly change the current project to be compatible with Java 10.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/quickfix-change-compliance-10.png" alt="quickfix change compliance 10" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect3"&gt; &lt;h4 id="java-editor"&gt;&lt;a class="anchor" href="#java-editor"&gt;&lt;/a&gt;Java Editor&lt;/h4&gt; &lt;div class="sect4"&gt; &lt;h5 id="quick-fix-to-add-nonnullbydefault-to-packages"&gt;&lt;a class="anchor" href="#quick-fix-to-add-nonnullbydefault-to-packages"&gt;&lt;/a&gt;Quick Fix to add @NonNullByDefault to packages&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;A new quick fix is offered to fix issues that are reported when the Missing &amp;apos;@NonNullByDefault&amp;apos; annotation on package warning is enabled. If the package already has a &lt;code&gt;&lt;code&gt;package-info.java&lt;/code&gt;&lt;/code&gt;, the quick fix can be invoked from the editor:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/add-nnbd-existing-packageinfo.png" alt="add nnbd existing packageinfo" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Otherwise, the quick fix must be invoked from the problems view, and will create a &lt;code&gt;&lt;code&gt;package-info.java&lt;/code&gt;&lt;/code&gt; with the required annotation:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/add-nnbd-create-packageinfo.png" alt="add nnbd create packageinfo" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;When invoked from the problems view, both variations of the quick fix can fix the problem for multiple packages simultaneously.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="navigate-to-switch-statement"&gt;&lt;a class="anchor" href="#navigate-to-switch-statement"&gt;&lt;/a&gt;Navigate to &amp;apos;switch&amp;apos; statement&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;You can now &lt;strong&gt;Ctrl+click&lt;/strong&gt; or use &lt;strong&gt;Open Declaration (F3)&lt;/strong&gt; on case or default keywords to quickly navigate to the beginning of the switch statement.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/navigate-to-switch.png" alt="navigate to switch" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="escape-non-ascii-characters-when-pasting-into-a-string-literal"&gt;&lt;a class="anchor" href="#escape-non-ascii-characters-when-pasting-into-a-string-literal"&gt;&lt;/a&gt;Escape non-ASCII characters when pasting into a string literal&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The &lt;strong&gt;Java &amp;gt; Editor &amp;gt; Typing &amp;gt; Escape text when pasting into a string literal&lt;/strong&gt; preference option now has a suboption &lt;strong&gt;Use Unicode escape syntax for non-ASCII characters&lt;/strong&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/escape-non-ascii-settings.png" alt="escape non ascii settings" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;When enabled, characters outside the visible ASCII range will be replaced by unicode escape sequences when pasted into a string:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/escape-non-ascii-example.png" alt="escape non ascii example" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="improved-java-syntax-coloring-in-the-dark-theme"&gt;&lt;a class="anchor" href="#improved-java-syntax-coloring-in-the-dark-theme"&gt;&lt;/a&gt;Improved Java syntax coloring in the dark theme&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;To improve readability in the dark theme, bold style usage has been reduced and some colors that were too close to each other have been altered.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/java-syntax-dark.png" alt="java syntax dark" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="improved-coloring-of-links-in-code-element-information-in-the-dark-theme"&gt;&lt;a class="anchor" href="#improved-coloring-of-links-in-code-element-information-in-the-dark-theme"&gt;&lt;/a&gt;Improved coloring of links in code element information in the dark theme&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The colors of links in code element information control now takes the color settings of the &lt;strong&gt;Hyperlink text color&lt;/strong&gt; and the &lt;strong&gt;Active hyperlink text color&lt;/strong&gt; from the &lt;strong&gt;Colors &amp;amp; Fonts&lt;/strong&gt; preference page into account. The readability in the dark theme has been improved a lot by this.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Before:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/element_info_before.png" alt="element info before" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;After:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/element_info_after.png" alt="element info after" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="improved-coloring-of-inherited-members-in-the-quick-outline-in-the-dark-theme"&gt;&lt;a class="anchor" href="#improved-coloring-of-inherited-members-in-the-quick-outline-in-the-dark-theme"&gt;&lt;/a&gt;Improved coloring of inherited members in the Quick Outline in the dark theme&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Eclipse default dark theme now includes styling of inherited members in JDT’s &lt;strong&gt;Quick Outline&lt;/strong&gt;. This improves readability in the dark theme a lot. The color can be configured via the &lt;strong&gt;Java &amp;gt; Inherited Members&lt;/strong&gt; color definition on the &lt;strong&gt;Colors and Fonts&lt;/strong&gt; preference page.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Before:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/inherited_before.png" alt="inherited before" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;After:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/inherited_after.png" alt="inherited after" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect3"&gt; &lt;h4 id="java-views-and-dialogs"&gt;&lt;a class="anchor" href="#java-views-and-dialogs"&gt;&lt;/a&gt;Java Views and Dialogs&lt;/h4&gt; &lt;div class="sect4"&gt; &lt;h5 id="test-sources"&gt;&lt;a class="anchor" href="#test-sources"&gt;&lt;/a&gt;Test sources&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;In the &lt;strong&gt;Java Build Path&lt;/strong&gt; project settings, there is now an attribute &lt;strong&gt;Contains test sources&lt;/strong&gt; to configure that a source folder contains test sources. (Note: test sources must have their own output folder). Similarly, for projects and libraries there is an attribute &lt;strong&gt;Visible only for test sources&lt;/strong&gt;. This setting also exists for classpath containers, and if it is set to &lt;strong&gt;Yes&lt;/strong&gt; for one of these, this value will be used for all contained libraries and projects.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/1-sourcefolder-settings-521330.png" alt="1 sourcefolder settings 521330" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Test source folders and dependencies are shown with a darker icon in the build path settings, the package explorer and other locations. This can be disabled in &lt;strong&gt;Preferences &amp;gt; Java &amp;gt; Appearance&lt;/strong&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/1a-modified-test-icon-preferences-530179.png" alt="1a modified test icon preferences 530179" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Referenced projects can contain test sources and have test dependencies themselves. Usually, when test sources are compiled, the test code in projects on the build path will be visible. As this is not always desirable, it can be changed by setting the new build path attribute &lt;strong&gt;Without test code&lt;/strong&gt;, that is available for projects, to &lt;strong&gt;Yes&lt;/strong&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/2-without-test-code-526858.png" alt="2 without test code 526858" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Build path entries configured like this have a decoration [without test code] after the project name, which can be disabled in &lt;strong&gt;Preferences &amp;gt; General &amp;gt; Appearance &amp;gt; Label Decorations&lt;/strong&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/2a-without-test-code-decorator-530179.png" alt="2a without test code decorator 530179" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;For each project, compilation is now done in two phases: First all main sources (which cannot see any test-code on the build-path) and then all test sources.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/3-visibilities-224708.png" alt="3 visibilities 224708" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;As a consequence, if the project is a modular Java 9 project, test dependencies like JUnit can not be referenced in the &lt;code&gt;&lt;code&gt;module-info.java&lt;/code&gt;&lt;/code&gt;, as they will not be visible while compiling it. The solution used to handle this is the same, that Maven uses: When test dependencies are put on the classpath, the module being compiled will automatically be configured to read the unnamed module during the compilation of the test sources, so the test dependencies will be visible.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Of course, code completion will not suggest test code in main sources:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/4a-completion-in-main-521331.png" alt="4a completion in main 521331" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;There are now two dynamic Java working sets &lt;strong&gt;Java Main Sources&lt;/strong&gt; and &lt;strong&gt;Java Test Sources&lt;/strong&gt; containing the source folders grouped according to value of the &lt;strong&gt;Contains test sources&lt;/strong&gt; attribute. This can for example be used to remove warnings in test sources from the problems view:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/5a-problems-view-521336.png" alt="5a problems view 521336" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;To achieve this, create a new filter that shows warnings for the &lt;strong&gt;Java Main Sources&lt;/strong&gt; working set and select it with the &lt;strong&gt;All Errors on Workspace&lt;/strong&gt; filter:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/5b-problems-view-filters-521336.png" alt="5b problems view filters 521336" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;There are also dedicated filters to quickly remove hits in main code or test code from Java search results:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/6-filter-search-result-521332.png" alt="6 filter search result 521332" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Similar, there is a filter to remove test code from &lt;strong&gt;Call hierarchies&lt;/strong&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/7-filter-call-hierarchy-521335.png" alt="7 filter call hierarchy 521335" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Another filter to remove test code exists for &lt;strong&gt;Quick type hierarchies&lt;/strong&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/8-filter-quick-type-hierarchy-521333.png" alt="8 filter quick type hierarchy 521333" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Test source folders will be preselected in the &lt;strong&gt;New JUnit Test Case&lt;/strong&gt; wizard&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/9-new-junit-332602.png" alt="9 new junit 332602" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;In Run and Debug configurations, the &lt;strong&gt;Classpath&lt;/strong&gt; tab (or &lt;strong&gt;Dependencies&lt;/strong&gt; tab when launching with Java 9) contains a new option &lt;strong&gt;Exclude Test Code&lt;/strong&gt;, that is automatically preselected when launching a Java Application from a source folder that is not marked to contain test sources:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/10-launching-529321.png" alt="10 launching 529321" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;When launching with Java 9 and this option is not selected, command line options will automatically be added so modules that have a non-empty classpath read the unnamed module. These command line options are part of what can be overridden using the new &lt;strong&gt;Override Dependencies&lt;/strong&gt; button.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="sort-library-entries-alphabetically-in-package-explorer"&gt;&lt;a class="anchor" href="#sort-library-entries-alphabetically-in-package-explorer"&gt;&lt;/a&gt;Sort library entries alphabetically in Package Explorer&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The content of libraries are displayed in the order of the classpath. This makes it difficult to find specific libraries by their name, especially when projects have many dependencies. The library entries can now be sorted alphabetically when setting the preference &lt;strong&gt;Sort library entries alphabetically in Package Explorer&lt;/strong&gt; on the &lt;strong&gt;Java &amp;gt; Appearance&lt;/strong&gt; preference page:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/jdt_sort_library_pref.png" alt="jdt sort library pref" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/jdt_library_entries_unsorted.png" alt="jdt library entries unsorted" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The default for this preference is &lt;strong&gt;OFF&lt;/strong&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="generate-dialogs-use-verbs-instead-of-ok"&gt;&lt;a class="anchor" href="#generate-dialogs-use-verbs-instead-of-ok"&gt;&lt;/a&gt;Generate dialogs use verbs instead of OK&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The &lt;strong&gt;Generate…​&lt;/strong&gt; dialogs of the Java tools have been adapted to use verbs instead of OK.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect3"&gt; &lt;h4 id="java-compiler"&gt;&lt;a class="anchor" href="#java-compiler"&gt;&lt;/a&gt;Java Compiler&lt;/h4&gt; &lt;div class="sect4"&gt; &lt;h5 id="option-for-regex-in-module-declaration-search"&gt;&lt;a class="anchor" href="#option-for-regex-in-module-declaration-search"&gt;&lt;/a&gt;Option for Regex in Module Declaration Search&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;This is an &lt;strong&gt;experimental&lt;/strong&gt; support provided to allow the regular expression usage in search field while searching for module declaration. This can be considered as a wrapper of the API change.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;To invoke the regular expression search from the search field under &lt;strong&gt;Java Search&lt;/strong&gt;, start the expression with &amp;quot;/r &amp;quot; i.e, a slash &amp;apos;/&amp;apos;, the letter &amp;apos;r&amp;apos; and a blank &amp;apos; &amp;apos; (not tab) followed by a regex, an example of which is shown below:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/mod.regex.trap.png" alt="mod.regex.trap" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;In the above example, all the characters trailing &amp;quot;/r &amp;quot; form a Java regular expression to denote a module name which starts with zero or more &amp;apos;n’s followed by the string &amp;quot;.ver&amp;quot; and followed again by zero or more number of arbitrary characters.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Another example would be to search for all modules that start with &lt;code&gt;&lt;code&gt;java.x&lt;/code&gt;&lt;/code&gt; followed by zero or more characters which is given by the regular expression &lt;code&gt;&lt;code&gt;/r java\.x.*&lt;/code&gt;&lt;/code&gt; - note the backslash for . to consider this as a &amp;quot;normal&amp;quot; character instead of the special regex].&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Yet another example would be search for all module names that start with j followed by zero or more characters and ending with .xml which in regex language translates to &lt;code&gt;&lt;code&gt;/r j.*\.xml&lt;/code&gt;&lt;/code&gt;. Please note that here the first &amp;apos;.&amp;apos; is the special regex character while the second &amp;apos;.&amp;apos; is escaped to denote that this is a normal character.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: You should use this only for &lt;strong&gt;Declarations&lt;/strong&gt; search for modules as it is not implemented for module references. Selecting &lt;strong&gt;All occurrences&lt;/strong&gt; in conjunction with regex will default to finding only the &lt;strong&gt;Declarations&lt;/strong&gt; matching the regex ignoring the references.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect3"&gt; &lt;h4 id="nonnullbydefault-per-module"&gt;&lt;a class="anchor" href="#nonnullbydefault-per-module"&gt;&lt;/a&gt;@NonNullByDefault per module&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;If a module is annotated with &lt;code&gt;&lt;code&gt;@NonNullByDefault&lt;/code&gt;&lt;/code&gt;, the compiler will interpret this as the global default for all types in this module:&lt;/p&gt; &lt;/div&gt; &lt;div class="listingblock"&gt; &lt;div class="content"&gt; &lt;pre class="prettyprint highlight"&gt;&lt;code class="language-java" data-lang="java"&gt;@org.eclipse.jdt.annotation.NonNullByDefault module my.nullsafe.mod { ...&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Note, however, that this requires an annotation type declared either with target &lt;code&gt;&lt;code&gt;ElementType.MODULE&lt;/code&gt;&lt;/code&gt;, or with no explicit target at all. Versions 2.2.0 and greater of bundle &lt;code&gt;&lt;code&gt;org.eclipse.jdt.annotation&lt;/code&gt;&lt;/code&gt; use the latter strategy and hence support a module-wide non-null default.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="nonnullbydefault-improvements"&gt;&lt;a class="anchor" href="#nonnullbydefault-improvements"&gt;&lt;/a&gt;@NonNullByDefault improvements&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;When using annotation-based null analysis, there are now more ways to define which unannotated locations are implicitly assumed to be annotated as &lt;code&gt;&lt;code&gt;@NonNull&lt;/code&gt;&lt;/code&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;&lt;code&gt;@NonNullByDefault&lt;/code&gt;&lt;/code&gt; annotations based on enum &lt;code&gt;&lt;code&gt;DefaultLocation&lt;/code&gt;&lt;/code&gt; can also be used if the primary nullness annotations are declaration annotations (previously this was supported only for &lt;code&gt;&lt;code&gt;TYPE_USE&lt;/code&gt;&lt;/code&gt; annotations).&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Support for &lt;code&gt;&lt;code&gt;@NonNullByDefault&lt;/code&gt;&lt;/code&gt; annotations that are targeted at parameters has been implemented.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Multiple different &lt;code&gt;&lt;code&gt;@NonNullByDefault&lt;/code&gt;&lt;/code&gt; annotations (especially with different default values) may be placed at the same target, in which case the sets of affected locations are merged.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Annotations which use a meta annotation &lt;code&gt;&lt;code&gt;@TypeQualifierDefault&lt;/code&gt;&lt;/code&gt; instead of a &lt;code&gt;&lt;code&gt;DefaultLocation&lt;/code&gt;&lt;/code&gt;-based specification are now understood, too, e.g. &lt;code&gt;&lt;code&gt;@org.springframework.lang.NonNullApi&lt;/code&gt;&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Version 2.2.0 of bundle &lt;code&gt;&lt;code&gt;org.eclipse.jdt.annotation&lt;/code&gt;&lt;/code&gt; contains an annotation type &lt;code&gt;&lt;code&gt;NonNullByDefault&lt;/code&gt;&lt;/code&gt; that can be applied to parameter and module declarations (in addition to the previously allowed targets).&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="test-sources-2"&gt;&lt;a class="anchor" href="#test-sources-2"&gt;&lt;/a&gt;Test sources&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;There is now support for running Java annotation processors on test sources. The output folder for files generated for these can be configured in the project properties in &lt;strong&gt;Java Compiler &amp;gt; Annotation Processing&lt;/strong&gt; as &lt;strong&gt;Generated test source directory&lt;/strong&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/testsources-apt-531072.png" alt="testsources apt 531072" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="new-preference-added-compiler-compliance-does-not-match-used-jre"&gt;&lt;a class="anchor" href="#new-preference-added-compiler-compliance-does-not-match-used-jre"&gt;&lt;/a&gt;New preference added &amp;quot;Compiler Compliance does not match used JRE&amp;quot;&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;A new preference &lt;strong&gt;Compiler Compliance does not match used JRE&lt;/strong&gt; is added to &lt;strong&gt;Compiler Preference Building Page&lt;/strong&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;This preference indicates the severity of the problem reported when project’s used JRE does not match the compiler compliance level selected. (e.g. a project using JRE 1.8 as JRE System Library, and the compiler compliance is set to 1.7).&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The value of this preference is by default WARNING.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;If the JRE being used is 9 or above and the &lt;strong&gt;--release&lt;/strong&gt; option is selected and even if the compiler compliance does not match the JRE being used, this option will be ignored.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;This preference can be set as shown below:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/jdt_compiler_compliance_mismatch_JRE.png" alt="jdt compiler compliance mismatch JRE" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect3"&gt; &lt;h4 id="java-formatter"&gt;&lt;a class="anchor" href="#java-formatter"&gt;&lt;/a&gt;Java Formatter&lt;/h4&gt; &lt;div class="sect4"&gt; &lt;h5 id="new-formatter-profile-page"&gt;&lt;a class="anchor" href="#new-formatter-profile-page"&gt;&lt;/a&gt;New formatter profile page&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The formatter profile preference page (&lt;strong&gt;Java &amp;gt; Code Style &amp;gt; Formatter &amp;gt; Edit…​&lt;/strong&gt;) has a new look which makes it much easier to set preferences for formatting Java code. Instead of multiple tabs, all preferences are presented in an expandable tree.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/formatter-profile-overview.png" alt="formatter profile overview" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;You can use &lt;strong&gt;filtering&lt;/strong&gt; to display only the settings with names matching a specific phrase. Filtering by values is also possible (prefix a value filter with a tilde).&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/formatter-profile-filtering.png" alt="formatter profile filtering" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Most sections have a &lt;strong&gt;Modify all&lt;/strong&gt; button in their header that lets you set all their preferences to the same value with one click.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/formatter-profile-modify-all.png" alt="formatter profile modify all" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Some preferences have more convenient controls. For example, number values can be easily modified with arrow buttons. Wrap policy settings are controlled by simple toolbars so that you can see and compare multiple policies at once.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/formatter-profile-wrap-settings.png" alt="formatter profile wrap settings" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;In the preview panel you can now use your own code to immediately see how it will be affected by the modified settings. You can also see the raw form of standard preview samples and make temporary modifications to them.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/formatter-profile-preview.png" alt="formatter profile preview" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="formatter-align-javadoc-tags-in-columns"&gt;&lt;a class="anchor" href="#formatter-align-javadoc-tags-in-columns"&gt;&lt;/a&gt;Formatter: align Javadoc tags in columns&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The formatter can now &lt;strong&gt;align names and/or descriptions&lt;/strong&gt; in Javadoc tags in new ways. The formatter profile editor is available for selection, under &lt;strong&gt;Comments &amp;gt; Javadoc&lt;/strong&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/formatter-javadoc-prefs.png" alt="formatter javadoc prefs" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;For example, the &lt;strong&gt;Align descriptions, grouped by type&lt;/strong&gt; setting is now used in the built-in Eclipse profile.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/formatter-javadoc-preview.png" alt="formatter javadoc preview" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The setting previously known as &lt;strong&gt;Indent Javadoc tags&lt;/strong&gt; is now called &lt;strong&gt;Align descriptions to tag width&lt;/strong&gt;. The two settings related to &lt;strong&gt;@param tags&lt;/strong&gt; also had their labels changed to better describe what they do.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="java-code-formatter-preferences-now-styled-for-the-dark-theme"&gt;&lt;a class="anchor" href="#java-code-formatter-preferences-now-styled-for-the-dark-theme"&gt;&lt;/a&gt;Java code formatter preferences now styled for the dark theme&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The formatter preferences tree styling has been fixed to work properly in the dark theme.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="new-cleanup-action-remove-redundant-modifiers"&gt;&lt;a class="anchor" href="#new-cleanup-action-remove-redundant-modifiers"&gt;&lt;/a&gt;New Cleanup Action &amp;quot;Remove redundant modifiers&amp;quot;&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The new cleanup action &amp;quot;Remove redundant modifiers&amp;quot; removes unnecessary modifiers on types, methods and fields. The following modifiers are removed:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Interface field declarations: &lt;code&gt;&lt;code&gt;public&lt;/code&gt;&lt;/code&gt;, &lt;code&gt;&lt;code&gt;static&lt;/code&gt;&lt;/code&gt;, &lt;code&gt;&lt;code&gt;final&lt;/code&gt;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Interface method declarations: &lt;code&gt;&lt;code&gt;public&lt;/code&gt;&lt;/code&gt;, &lt;code&gt;&lt;code&gt;abstract&lt;/code&gt;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Nested interfaces: &lt;code&gt;&lt;code&gt;static&lt;/code&gt;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Method declarations in final classes: &lt;code&gt;&lt;code&gt;final&lt;/code&gt;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The cleanup action can be configured as save action on the &lt;strong&gt;Unnecessary Code&lt;/strong&gt; page.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/jdt_remove_redundant_modifiers.png" alt="jdt remove redundant modifiers" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect3"&gt; &lt;h4 id="debug"&gt;&lt;a class="anchor" href="#debug"&gt;&lt;/a&gt;Debug&lt;/h4&gt; &lt;div class="sect4"&gt; &lt;h5 id="launch-configuration-prototypes-for-java-launch-configurations"&gt;&lt;a class="anchor" href="#launch-configuration-prototypes-for-java-launch-configurations"&gt;&lt;/a&gt;Launch configuration prototypes for Java Launch Configurations&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;A Java Launch Configuration can now be based on a prototype.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/prototype-java-launch-configuration.png" alt="prototype java launch configuration" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;A prototype seeds attributes in its associated Java Launch Configurations with the settings specified in the Prototype tab.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/prototype-tab-java-launch-configuration-1.png" alt="prototype tab java launch configuration 1" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Once a Java Launch Configuration has been created, you can override any initial settings from the prototype. You can also reset the settings of a Java Launch Configuration with the ones from its prototype. A Java Launch Configuration maintains a link to its prototype, but is a complete stand-alone launch configuration that can be launched, exported, shared, etc.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/prototype-tab-java-launch-configuration-2.png" alt="prototype tab java launch configuration 2" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="advanced-source-lookup-implementation"&gt;&lt;a class="anchor" href="#advanced-source-lookup-implementation"&gt;&lt;/a&gt;Advanced source lookup implementation&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;More precise &lt;strong&gt;advanced&lt;/strong&gt; source lookup implementation, particularly useful when debugging applications that load classes dynamically at runtime.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;New &lt;code&gt;&lt;code&gt;org.eclipse.jdt.launching.workspaceProjectDescribers&lt;/code&gt;&lt;/code&gt; extension point can be used to enable advanced source lookup for projects with non-default layout, like PDE Plug-In projects.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;New &lt;code&gt;&lt;code&gt;org.eclipse.jdt.launching.sourceContainerResolvers&lt;/code&gt;&lt;/code&gt; can be used to download sources jar files from remote artifact repositories, like Maven Central or Eclipse P2.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Advanced source lookup affects debug launches only and can be enabled or disabled with &lt;strong&gt;Java &amp;gt; Debug &amp;gt; Use advanced source lookup (JRE 1.5 and higher)&lt;/strong&gt; preference option:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/advanced-source-lookup.png" alt="advanced source lookup" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="debugger-listens-to-thread-name-changes"&gt;&lt;a class="anchor" href="#debugger-listens-to-thread-name-changes"&gt;&lt;/a&gt;Debugger listens to thread name changes&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;&lt;strong&gt;Debug view&lt;/strong&gt; now automatically updates thread names if they are changed in the debuggee JVM. This shows live information for worker instances, as described above.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Technically speaking, Java debugger automatically adds a new (user invisible) breakpoint in the JVM and notifies clients (like Debug view) on a breakpoint hit. If this behavior is undesired for some reason, product owners can disable it via product customization.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The property value is: &lt;strong&gt;org.eclipse.jdt.debug.ui/org.eclipse.jdt.debug.ui.javaDebug.ListenOnThreadNameChanges=false&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="value-displayed-for-method-exit-and-exception-breakpoints"&gt;&lt;a class="anchor" href="#value-displayed-for-method-exit-and-exception-breakpoints"&gt;&lt;/a&gt;Value displayed for method exit and exception breakpoints&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;When a &lt;strong&gt;method exit breakpoint&lt;/strong&gt; is hit, the value being returned is now shown in the variables view.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/returningvalue.png" alt="returningvalue" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Similarly, when an &lt;strong&gt;exception breakpoint&lt;/strong&gt; is hit, the exception being thrown is shown.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/throwingexception.png" alt="throwingexception" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="display-view-renamed-to-debug-shell"&gt;&lt;a class="anchor" href="#display-view-renamed-to-debug-shell"&gt;&lt;/a&gt;Display view renamed to Debug Shell&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The &lt;strong&gt;Display view&lt;/strong&gt; has been renamed to &lt;strong&gt;Debug Shell&lt;/strong&gt; to better match the features and purpose of this view. Also, a java comment is shown in the Debug Shell on fresh open that explains when and how to use it.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://www.eclipse.org/eclipse/news/4.8/images/debugShell.png" alt="debugShell" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="and-more"&gt;&lt;a class="anchor" href="#and-more"&gt;&lt;/a&gt;And more…​&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;You can find more noteworthy updates in on &lt;a href="https://tools.jboss.org/documentation/whatsnew/jbosstools/4.6.0.Final.html"&gt;this page&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="what-is-next"&gt;&lt;a class="anchor" href="#what-is-next"&gt;&lt;/a&gt;What is next?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Having JBoss Tools 4.6.0 and Red Hat Developer Studio 12.0 out we are already working on the next release for Eclipse 2018-09.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Enjoy!&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Jeff Maury&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/bzeusGCgaZA" height="1" width="1" alt=""/&gt;</content><summary>JBoss Tools 4.6.0 and Red Hat Developer Studio 12.0 for Eclipse Photon are here waiting for you. Check it out! Installation Red Hat Developer Studio comes with everything pre-bundled in its installer. Simply download it from our Red Hat Developer product page and run it like this: java -jar devstudio-&lt;installername&gt;.jar JBoss Tools or Bring-Your-Own-Eclipse (BYOE) Developer Studio require a bit more: This release requires at least Eclipse 4.8 (Photon) but we recommend using the latest Eclipse 4.8 Photon JEE Bundle since then you get most of the dependencies preinstalled. Once you have installed Eclipse, you can either find us on the Eclipse Marketplace under "JBoss Tools" or...</summary><dc:creator>jeffmaury</dc:creator><dc:date>2018-07-17T00:00:00Z</dc:date><feedburner:origLink>https://tools.jboss.org/blog/12.0.0.ga-for-photon.html</feedburner:origLink></entry><entry><title>Byteman 4.0.4 has been released</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/XTfLQ3WoaK0/byteman-404-has-been-released.html" /><category term="feed_group_name_byteman" scheme="searchisko:content:tags" /><category term="feed_name_byteman" scheme="searchisko:content:tags" /><author><name>Andrew Dinn</name></author><id>searchisko:content:id:jbossorg_blog-byteman_4_0_4_has_been_released</id><updated>2018-07-16T20:34:00Z</updated><published>2018-07-16T20:34:00Z</published><content type="html">Byteman 4.0.4 is now available from the &lt;a href="http://www.jboss.org/byteman/downloads"&gt;Byteman downloads page&lt;/a&gt; and from the &lt;a href="https://oss.sonatype.org/index.html#nexus-search;quick%7Ebyteman"&gt;Maven Central repository&lt;/a&gt;. It is the latest release for use on JDK9+ runtimes. It is also recommended as the preferred release for use on JDK8- runtimes.&lt;br /&gt;&lt;br /&gt;Byteman 4.0.3 updates the 4.0.3 release to ensure that it works&amp;nbsp; correctly on the latest jdk11 releases. Specifically, it ensures that Byteman is able to process class files with a JDK11 class file version (the previous release would run on jdk11 but could only classes whose bytecode file version was for jdk10 or lower. More details can be found in the &lt;a href="http://downloads.jboss.org/byteman/4.0.4/ReleaseNotes.txt"&gt;Release Notes&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/XTfLQ3WoaK0" height="1" width="1" alt=""/&gt;</content><summary>Byteman 4.0.4 is now available from the Byteman downloads page and from the Maven Central repository. It is the latest release for use on JDK9+ runtimes. It is also recommended as the preferred release for use on JDK8- runtimes. Byteman 4.0.3 updates the 4.0.3 release to ensure that it works  correctly on the latest jdk11 releases. Specifically, it ensures that Byteman is able to process class fil...</summary><dc:creator>Andrew Dinn</dc:creator><dc:date>2018-07-16T20:34:00Z</dc:date><feedburner:origLink>http://bytemanblog.blogspot.com/2018/07/byteman-404-has-been-released.html</feedburner:origLink></entry><entry><title>Red Hat Process Automation Manager v7.0</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Rt6jvJVSi8E/red-hat-process-automation-manager-v70.html" /><category term="feed_group_name_jbpm" scheme="searchisko:content:tags" /><category term="feed_name_kverlaen" scheme="searchisko:content:tags" /><category term="jBPM" scheme="searchisko:content:tags" /><category term="jbpm7" scheme="searchisko:content:tags" /><category term="Process Automation Manager" scheme="searchisko:content:tags" /><category term="product" scheme="searchisko:content:tags" /><category term="release" scheme="searchisko:content:tags" /><author><name>Kris Verlaenen</name></author><id>searchisko:content:id:jbossorg_blog-red_hat_process_automation_manager_v7_0</id><updated>2018-07-16T15:38:32Z</updated><published>2018-07-16T15:38:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div style="text-align: justify;"&gt;jBPM is completely open-source and therefore most of my blogs are typically about the latest and greatest feature that was just introduced in the community.&amp;nbsp; However, Red Hat also offers a supported version, with the testing, certification, and maintenance releases necessary for enterprise production use (for a quick intro on potential differences, take for example a look &lt;a href="https://www.redhat.com/en/technologies/jboss-middleware/community-or-enterprise"&gt;here&lt;/a&gt;).&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;And recently, as announced in this &lt;a href="https://www.redhat.com/en/about/press-releases/red-hat-unveils-next-generation-process-automation-offering"&gt;press release&lt;/a&gt;, Red Hat unveiled &lt;b&gt;&lt;a href="https://www.redhat.com/en/technologies/jboss-middleware/process-automation-manager"&gt;&lt;i&gt;Red Hat Process Automation Manager 7&lt;/i&gt;&lt;/a&gt;.&lt;/b&gt;&amp;nbsp; The most obvious change you might notice immediately is that the product was renamed - formerly known as Red Hat JBoss BPM Suite.&amp;nbsp; Since jBPM has evolved beyond just BPM - with features such as decision management, case management and constraint solving closely integrated - it was time to also reflect that in the product naming.&amp;nbsp; Similarly, &lt;a href="https://www.redhat.com/en/technologies/jboss-middleware/decision-manager"&gt;&lt;i&gt;Red Hat Decision Manager 7&lt;/i&gt;&lt;/a&gt; was released a few months ago, focusing on the Drools and Optaplanner bits.&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;However, nothing changes structurally.&amp;nbsp; Red Hat Process Automation Manager is based on jBPM (to be more precise, it was based on the jBPM 7.7.0.Final release) and actually is a super-set of Red Hat Decision Manager, so it also includes all the rules and constraint solving capabilities as well (Drools and Optaplanner).&amp;nbsp; Since it is completely open-source, you will see the same set of components there as you see in the community: the process execution server (kie-server), the web-based console (business-central aka the workbench - for both authoring and runtime deployment and administration), smart router, controller, Eclipse tooling, etc.&amp;nbsp; OpenShift images and templates (supporting these capabilities in the cloud) are available too for those targeting cloud deployment.&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;Red Hat Process Automation Manager also includes an advanced open source user experience platform from Red Hat partner &lt;i&gt;Entando&lt;/i&gt;. It can be used to quickly develop modern UI/UX layers for user interaction with business process applications, including a drag &amp;amp; drop UI development tool with widgets to create task lists, forms, process graphs, etc. &lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;Red Hat Process Automation Manager is part of the &lt;a href="https://www.redhat.com/en/topics/automation/whats-business-automation"&gt;Business Automation portfolio&lt;/a&gt;, which includes Red Hat Process Automation Manager and Red Hat Decision Manager, but also the Red Hat Mobile Application Platform and in the future also big data analytics through Daikon.&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;More questions?&amp;nbsp; Take a look at the &lt;a href="https://www.redhat.com/en/technologies/jboss-middleware/process-automation-manager"&gt;product pages&lt;/a&gt; !&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Rt6jvJVSi8E" height="1" width="1" alt=""/&gt;</content><summary>jBPM is completely open-source and therefore most of my blogs are typically about the latest and greatest feature that was just introduced in the community.  However, Red Hat also offers a supported version, with the testing, certification, and maintenance releases necessary for enterprise production use (for a quick intro on potential differences, take for example a look here). And recently, as a...</summary><dc:creator>Kris Verlaenen</dc:creator><dc:date>2018-07-16T15:38:00Z</dc:date><feedburner:origLink>http://kverlaen.blogspot.com/2018/07/red-hat-process-automation-manager-v70.html</feedburner:origLink></entry><entry><title>Smart-Meter Data Processing Using Apache Kafka on OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/-PJfr6kKpKI/" /><category term="JBoss A-MQ" /><category term="Red Hat OpenShift Container Platform" /><category term="amq" /><category term="Apache Kafka" /><category term="big data" /><category term="data streaming" /><category term="Internet of Things" /><category term="Kafka streams" /><category term="microservices" /><category term="OpenShift Container Platform" /><category term="Red Hat AMQ" /><category term="Red Hat OpenShift" /><category term="Strimzi" /><author><name>Hugo Hiden</name></author><id>https://developers.redhat.com/blog/?p=506407</id><updated>2018-07-16T11:00:44Z</updated><published>2018-07-16T11:00:44Z</published><content type="html">&lt;p&gt;There is a major push in the United Kingdom to replace aging mechanical electricity meters with connected smart meters. New meters allow consumers to more closely monitor their energy usage and associated cost, and they enable the suppliers to automate the billing process because the meters automatically report fine-grained energy use.&lt;/p&gt; &lt;p&gt;This post describes an architecture for processing a stream of meter readings using &lt;a href="http://strimzi.io/"&gt;Strimzi&lt;/a&gt;, which offers support for running Apache Kafka in a container environment (&lt;a href="https://www.openshift.com/"&gt;Red Hat OpenShift&lt;/a&gt;). The data has been made available through a &lt;a href="http://www.networkrevolution.co.uk/"&gt;UK research project&lt;/a&gt; that collected data from energy producers, distributors, and consumers from 2011 to 2014. The TC1a dataset used here contains data from 8,000 domestic customers on half-hour intervals in the following form:&lt;/p&gt; &lt;p&gt;&lt;span id="more-506407"&gt;&lt;/span&gt;&lt;/p&gt; &lt;pre&gt;&lt;strong&gt; Location ID,Measurement Description,Parameter Type and Units,of capture,Parameter&lt;/strong&gt; 120,Electricity supply meter,Consumption in period [kWh],03/12/2011 00:00:00,0.067 120,Electricity supply meter,Consumption in period [kWh],03/12/2011 00:30:00,0.067 120,Electricity supply meter,Consumption in period [kWh],03/12/2011 01:00:00,0.066 120,Electricity supply meter,Consumption in period [kWh],03/12/2011 01:30:00,0.066&lt;/pre&gt; &lt;p&gt;As a single year of data represents approximately 25GB of comma-separated value (CSV) data, so importing and analyzing this data on a single machine is challenging. Also, when considering the relatively small number of customers monitored (8,000) in comparison with the number of actual customers served by any reasonably sized power company, the difficulties in processing this stream of data are magnified.&lt;/p&gt; &lt;p&gt;The approach adopted here is to process this data in the form of a stream of readings and make use of the &lt;a href="https://developers.redhat.com/blog/2018/05/07/announcing-amq-streams-apache-kafka-on-openshift/"&gt;Red Hat AMQ Streams&lt;/a&gt; distributed streaming platform to perform aggregations in real time as data is ingested into the application. The outputs of the system will be twofold: a dataset that can be used to train models of consumer use over a 24-hour period and a monitoring dashboard showing live demand levels.&lt;/p&gt; &lt;h2&gt;Components&lt;/h2&gt; &lt;p&gt;In order to architect a system that could scale to be deployed in a production environment, we adopted a microservices approach deployed on Red Hat OpenShift. The microservices are connected via Apache Kafka topics in the following pipeline:&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter size-full wp-image-506427 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/07/architecture-1024x768.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/07/architecture.png" alt="" width="1024" height="768" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/07/architecture.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/07/architecture-300x225.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/07/architecture-768x576.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;br /&gt; Each of these blocks is deployed individually within OpenShift and makes use of an Apache Kafka Cluster provided by AMQ Streams.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://github.com/cloudevents/spec"&gt;CloudEvents specification&lt;/a&gt; aims to enable portability of applications across multiple cloud providers. This is an ideal fit for describing the meter reading values that are sent from smart meters (or a simulator, in our case) to the energy supplier. Such portability will enable customers to change their electricity supplier without needing to change the hardware in their homes.&lt;/p&gt; &lt;h3&gt;REST Endpoint&lt;/h3&gt; &lt;p&gt;Data is ingested into the system via a Smart-Meter Simulator (which just reads the CSV data file) on a reading-by-reading basis. These meter readings are sent as CloudEvents to a RESTEasy microservice running as a Thorntail application. The application is deployed to OpenShift using the Fabric8 Maven plugin and converts the CloudEvents into Apache Kafka messages stored by AMQ Streams. This microservice makes use of the &lt;a href="https://github.com/aerogear/kafka-cdi"&gt;Kafka CDI library&lt;/a&gt;, which enables interaction with Apache Kafka topics via simple CDI annotations within Java code. This means that to connect to an Apache Kafka topic and send data to it, the amount of code is dramatically reduced to this:&lt;/p&gt; &lt;pre&gt;@ApplicationScoped @Path("/clnr") @KafkaConfig(bootstrapServers = "#{KAFKA_SERVICE_HOST}:#{KAFKA_SERVICE_PORT}") public class IngestAPI { private static final SimpleDateFormat format = new SimpleDateFormat("yyyy/MM/dd HH:mm:ss"); private final static Logger logger = Logger.getLogger(IngestAPI.class.getName()); @Producer private SimpleKafkaProducer&amp;#60;String, Reading&amp;#62; myproducer; &lt;/pre&gt; &lt;p&gt;The &lt;code&gt; @KafkaConfig &lt;/code&gt; annotation defines the location of the Apache Kafka cluster that will be used. This configuration can be entered directly or, if the data is formatted as &lt;code&gt; #{VALUE}&lt;/code&gt;, it will be taken from environment variables. This is useful when deploying the service into OpenShift as environment variables that are a key route for adding configuration data to deployments. The &lt;code&gt; @Producer &lt;/code&gt; annotation defines an output to an Apache Kafka topic where the code can send messages. Changes to the application configuration are handled transparently by OpenShift; a container is restarted if its configuration changes.&lt;/p&gt; &lt;p&gt;As part of any stream processing application, the correct consideration of timestamps within the data is essential. By default, the Apache Kafka Streams API adopts the system time (that is, wall clock time) when processing messages. So, if a message has been placed onto a topic without a timestamp in place, the default behavior will be to add a timestamp representing the current instance in time. Given that the data we are processing has been generated by other systems at a prior time to it being received, we need to configure Apache Kafka to use a timestamp that is embedded in the message payload.&lt;/p&gt; &lt;p&gt;There are two ways of achieving this:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Tell Apache Kafka to use a timestamp extractor class to explicitly pull a timestamp from the messages. Apache Kafka provides a mechanism for doing this when attaching the Streams API to a topic.&lt;/li&gt; &lt;li&gt;Add a timestamp to a message before it is placed onto a topic. This is the approach adopted in this example, primarily because the Kafka CDI library does not yet support the declaration of a timestamp extractor class in the streams annotation.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;To include a timestamp in a message, a new &lt;code&gt;ProducerRecord&lt;/code&gt; object must be created with the required metadata:&lt;/p&gt; &lt;pre&gt;Long timetamp = reading.getReadingTime(); String key = reading.getCustomerId(); ProducerRecord&amp;#60;String, Reading&amp;#62;; record = new ProducerRecord&amp;#60;&amp;#62;(“readings”, null, timestamp, key, reading); ((org.apache.kafka.clients.producer.Producer)myproducer).send(record); &lt;/pre&gt; &lt;p&gt;Here are some points to consider:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The timestamp and key are obtained directly from the parsed meter reading created when a row of data is posted into the ingest API.&lt;/li&gt; &lt;li&gt;It is necessary to explicitly cast the &lt;code&gt;SimpleKafkaProducer&lt;/code&gt; injected by the Kafka CDI library into an Apache Kafka &lt;code&gt;Producer&lt;/code&gt; object in order to be able to send a &lt;code&gt;ProducerRecord&lt;/code&gt; directly. When the Kafka CDI library is extended to include a timestamp extractor class annotation, this code to directly insert a timestamp would no longer be necessary.&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Current Demand-Level Calculator&lt;/h3&gt; &lt;p&gt;The purpose of the demand-level aggregator is to collect all of the readings in a one-hour period for all of the consumers in the dataset in order to provide an hour-by-hour demand level. In order to do this using the Apache Kafka Streams API, we need to aggregate the data into a rolling one-hour window. The code for this is shown below:&lt;/p&gt; &lt;pre&gt;@KafkaStream(input="ingest.api.out", output="demand.out") public KStream&amp;#60;String, JsonObject&amp;#62; demandStream(final KStream&amp;#60;String, JsonObject&amp;#62; source) { return source /*.peek((k, v)-&amp;#62;v.toString())*/ .selectKey((key, value) -&amp;#62; { return "ALL"; }).map((key, value) -&amp;#62; { MeterReading mr = new MeterReading(); mr.setCustomerId(value.getString("customerId")); mr.setTimestamp(value.getString("timestamp")); mr.setValue(value.getJsonNumber("kWh").doubleValue()); return new KeyValue&amp;#60;&amp;#62;(key, mr); }) .groupByKey(Serialized.with(new Serdes.StringSerde(), CafdiSerdes.Generic(MeterReading.class))) .windowedBy(TimeWindows.of(1 * 60 * 60 * 1000).until(1 * 60 * 60 * 1000)) .aggregate(() -&amp;#62; 0.0, (k, v, a) -&amp;#62; a + v.value, Materialized.&amp;#60;String, Double, WindowStore&amp;#60;Bytes, byte[]&amp;#62;&amp;#62;as("demand-store") .withValueSerde(Serdes.Double()) .withKeySerde(Serdes.String())) .toStream().map(new KeyValueMapper&amp;#60;Windowed&amp;#60;String&amp;#62;, Double, KeyValue&amp;#60;String, JsonObject&amp;#62;&amp;#62;() { @Override public KeyValue&amp;#60;String, JsonObject&amp;#62; apply(Windowed&amp;#60;String&amp;#62; key, Double value) { JsonObjectBuilder builder = Json.createObjectBuilder(); builder.add("timedate", format.format(new Date(key.window().start()))) .add("hour", hourFormat.format(new Date(key.window().start()))) .add("day", dayFormat.format(new Date(key.window().start()))) .add("timestamp", key.window().start()) .add("demand", value); return new KeyValue&amp;#60;&amp;#62;("DEMAND", builder.build()); } } ) &lt;/pre&gt; &lt;p&gt;In this code, there are a number of distinct steps to perform:&lt;/p&gt; &lt;p&gt;&lt;code&gt;.selectKey((key, value)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;When the data is ingested, the data in the input stream is keyed by customer ID; however, in this aggregation we want to group data from all users into a single set of time windows that represent the usage data for a particular hour. In order to do this, we apply a &lt;code&gt;selectKey&lt;/code&gt; operator that simply replaces the &lt;code&gt;customerId&lt;/code&gt; field with a default key of &lt;code&gt;“ALL”&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;&lt;code&gt;map((key, value)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;The data passed between the various steps in this prototype is formatted as plain JSON as a lowest-common-denominator format. We are going to treat the data as a stream of &lt;code&gt;MeterReading objects&lt;/code&gt;, so this &lt;code&gt;map&lt;/code&gt; operator parses each record in the stream in turn and returns instances of the &lt;code&gt;MeterReading&lt;/code&gt; Java object.&lt;/p&gt; &lt;p&gt;&lt;code&gt;groupByKey&lt;/code&gt;&lt;/p&gt; &lt;p&gt;To perform any windowing operators, the Apache Kafka Streams API requires us to group the incoming data into a &lt;code&gt;KGroupedStream&lt;/code&gt;. Because we have already replaced the &lt;code&gt;customerId&lt;/code&gt; field with a standard key, this operator produces a grouped stream with a single group within it.&lt;/p&gt; &lt;p&gt;&lt;code&gt;.windowedBy(TimeWindows.of(1*60*60*1000).until(1*60*60*1000))&lt;/code&gt;&lt;/p&gt; &lt;p&gt;This is the operation that collects data from the input stream of meter readings into one-hour long windows of readings. In order to cater to some out-of-order events such as delayed readings, we retain this window of data for one hour after its time span. This allows us to insert events into this window up to one hour after they were expected to arrive. This parameter is clearly tunable and in a real system would be adjusted to balance between having results produced in an acceptable time span and potentially ignoring data that arrives too late.&lt;/p&gt; &lt;p&gt;&lt;code&gt;.aggregate(() -&amp;#62;0.0, (k, v, a) -&amp;#62; a + v.value&lt;/code&gt;&lt;/p&gt; &lt;p&gt;This step performs the actual work of adding up all of the meter readings in a single time window. The values are summed using an aggregator, which is initialized as a double-precision value of 0.0 and, when new readings fall within the window, this value is updated with the current meter reading value.&lt;/p&gt; &lt;p&gt;&lt;code&gt;public KeyValue&amp;#60;String,JsonObject&amp;#62; apply(Windowed&amp;#60;String&amp;#62;key,Double value)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Once we have a stream of total values for each time window, we apply another mapping function to these to add extra data such as timestamps, hour of data, and so on. This stream is then passed on to the downstream topics as JSON objects.&lt;/p&gt; &lt;h3&gt;Demand-Level Web Application&lt;/h3&gt; &lt;p&gt;Once a stream of hourly total demand level has been produced, the next step in the pipeline is to display this data via a simple visualization. Because the nature of this prototype is to investigate the feasibility of using Apache Kafka streams to process smart-meter data, the visualization in this demo is extremely simple in nature and just displays a bar chart that is updated when new hourly demand levels are available.&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter size-full wp-image-506497 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/07/image-1024x399.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/07/image.png" alt="" width="2114" height="824" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/07/image.png 2114w, https://developers.redhat.com/blog/wp-content/uploads/2018/07/image-300x117.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/07/image-768x299.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/07/image-1024x399.png 1024w" sizes="(max-width: 2114px) 100vw, 2114px" /&gt;&lt;/p&gt; &lt;p&gt;In addition to the web chart, two other components are present in this application:&lt;/p&gt; &lt;h4&gt;Kafka CDI Topic Connection&lt;/h4&gt; &lt;p&gt;This component uses the simplest form of the Kafka CDI library to create a consumer method that receives demand-level JSON objects from the output of the demand-level calculator application:&lt;/p&gt; &lt;pre&gt;@ApplicationScoped @KafkaConfig(bootstrapServers = "#{KAFKA_SERVICE_HOST}:#{KAFKA_SERVICE_PORT}") public class DemandStreamListener { public DemandStreamListener() { System.out.println("Started demand stream listener"); } private static final Logger logger = Logger.getLogger(DemandStreamListener.class.getName()); @Consumer(topics = "demand.out", groupId = "1") public void onMessage(String key, JsonObject json){ logger.info(json.toString()); DemandWS.sendDemand(json); } &lt;/pre&gt; &lt;p&gt;The key part of this code is the &lt;code&gt;@Consumer&lt;/code&gt; annotation, which attaches to the Apache Kafka topic and marks the &lt;code&gt;onMessage&lt;/code&gt; method as the receiver for &lt;code&gt;JsonObject&lt;/code&gt; messages from the &lt;code&gt;demand.out&lt;/code&gt; Apache Kafka topic. As soon as messages are received, they are simply passed directly to the &lt;code&gt;DemandWS&lt;/code&gt; websocket.&lt;/p&gt; &lt;h4&gt;Websocket Handling&lt;/h4&gt; &lt;p&gt;In order to pass messages directly to the browser to support dynamic chart updating, we create a simple WebSocket endpoint that just keeps a list of connected WebSockets and passes demand level messages to each, in turn, every time a new message is received from the Kafka topic:&lt;/p&gt; &lt;pre&gt;@ServerEndpoint("/ws") @ApplicationScoped public class DemandWS { private static final Logger logger = Logger.getLogger(DemandWS.class.getName()); public static final Map&amp;#60;String, Session&amp;#62; clients = new ConcurrentHashMap&amp;#60;&amp;#62;(); @OnOpen public void socketOpened(Session client){ logger.info("Socked Opened: " + client.getId()); clients.put(client.getId(), client); } @OnClose public void socketClosed(Session client){ logger.info("Socket Closed: " + client.getId()); clients.remove(client.getId()); } public static void sendDemand(JsonObject demandMessage){ for(Session client : clients.values()){ client.getAsyncRemote().sendText(demandMessage.toString()); } } } &lt;/pre&gt; &lt;p&gt;The WebSocket implementation is extremely simple: it uses the &lt;code&gt;@ServiveEndpoint&lt;/code&gt; annotation to mark it as a WebSocket endpoint. This then allows clients to connect and receive real-time updates. The implementation tracks the lifecycle of the client connections so that messages can be routed to the currently active clients when new demand-level Apache Kafka messages are received.&lt;/p&gt; &lt;h3&gt;Customer Profile Aggregator&lt;/h3&gt; &lt;p&gt;The aim of the Customer Profile Aggregator microservice is to construct average usage patterns across the day for each customer. This is divided into 24-hour values representing the average amount of energy that a customer uses in that hour. These values can be combined with other datasets and used in machine learning applications, for example, to predict social class or future usage patterns for capacity planning.&lt;/p&gt; &lt;p&gt;As with the microservice that calculates the current demand, the profile aggregator makes use of the Apache Kafka Streams API to process the data.&lt;/p&gt; &lt;pre&gt;source.selectKey((key, value) -&amp;#62; value.getString("customerId")) .groupByKey(Serialized.with(new Serdes.StringSerde(), new MeterReadingSerializer())) .aggregate(()-&amp;#62;new CustomerRecord(), (k, v, a)-&amp;#62; a.update(v), CafdiSerdes.Generic(CustomerRecord.class)) .toStream().map((k, v)-&amp;#62;{ String json = ""; try { json = mapper.writeValueAsString(v); } catch (Exception e){ e.printStackTrace(); } return new KeyValue&amp;#60;&amp;#62;(v.customerId, json); }); &lt;/pre&gt; &lt;p&gt;Processing the data using the Apache Kafka Streams API is straightforward. Initially, records are grouped by the ID of the customer they relate to. Following this, they are converted to a &lt;code&gt;CustomerRecord&lt;/code&gt; object. This object contains a bucket for each hour of the day holding the energy used in that hour. When the &lt;code&gt;CustomerRecord&lt;/code&gt; for each customer is updated with a new &lt;code&gt;MeterReading&lt;/code&gt;, the relevant bucket is updated. Finally, the output is written as a JSON-formatted stream of &lt;code&gt;CustomerRecords&lt;/code&gt;. These records are persisted to a database to allow them to be consumed by other applications that are not necessarily developed in a streaming-aware manner.&lt;/p&gt; &lt;p&gt;There is a download REST service that can query this database to give the current hourly usage profiles of all of the customers in the form of a CSV file that can be imported into spreadsheets for analysis or used for machine learning and customer classification.&lt;/p&gt; &lt;h3&gt;Packaging the Components&lt;/h3&gt; &lt;p&gt;Because we are running this stack within OpenShift and making use of the AMQ Streams–packaged Apache Kafka platform, there are some considerations to be made when packaging and deploying the various components. Where applicable, the components are packaged as microservices using WildFly Swarm with the microprofile features enabled. This is reflected in the &lt;code&gt;pom.xml&lt;/code&gt; dependencies on &lt;code&gt;org.wildfly.swarm:microprofile&lt;/code&gt; and &lt;code&gt;org.aerogear.kafka:kafka-cdi-extensions&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;These dependencies are sufficient to enable the CDI environment that manages the injection of Apache Kafka connections which are used to transport messages. One thing that this does not provide yet, however, is the deployment and management of the requisite Apache Kafka topics which need to be present for the Kafka CDI injection process to work. Fortunately, AMQ Streams provides a route for declaratively creating Apache Kafka topics via config maps, which are an OpenShift/Kubernetes mechanism for providing key:value configuration properties to deployed applications.&lt;/p&gt; &lt;p&gt;To create a new topic, the following &lt;code&gt;ConfigMap&lt;/code&gt; entries need to be created:&lt;/p&gt; &lt;pre&gt;apiVersion: v1 kind: ConfigMap metadata: name: demand.out labels: strimzi.io/kind: topic strimzi.io/cluster: my-cluster data: name: demand.out partitions: "2" replicas: "1" &lt;/pre&gt; &lt;p&gt;The critical sections of this map lie in the &lt;code&gt;labels&lt;/code&gt; attributes. The AMQ Streams operator continuously monitors the config maps within the environment, and when maps containing the &lt;code&gt;strimzi.io&lt;/code&gt; labels appear, the operator will take steps to manage any required Apache KSt topics. The data section in the config map contains the actual details of the topics to be deployed.&lt;/p&gt; &lt;p&gt;Config maps like this are packaged as YAML files and deployed as part of the application using the Fabric8 Maven plugin. The Fabric8 plugin aims to simplify the deployment of microservices in both Kubernetes and OpenShift container environments and provides facilities for packaging up code and configuration into a single deployable unit. By convention, we packaged up the parts of this demo along with configurations for the output topics for each component. By doing this, once all components were deployed, we were left with a fully connected set of deployments exchanging Apache Kafka messages via topics to process the smart-meter data in real time as it was posted to the ingest API endpoint.&lt;/p&gt; &lt;h2&gt;Conclusions&lt;/h2&gt; &lt;p&gt;Apache Kafka and the Streams API make it fairly easy to perform the kinds of real-time aggregations needed to process this type of data stream. The operators provided for windowing and grouping coupled with the opportunities to add custom aggregators, mapping functions, and so on make for a rich set of stream-processing capabilities.&lt;/p&gt; &lt;p&gt;The Strimzi distribution of Apache Kafka makes it straightforward to deploy a tested, performant Apache Kafka cluster within a container environment with very little configuration effort. This allowed us to focus on the actual stream operators required to process the data&lt;/p&gt; &lt;p&gt;Running the demo in OpenShift provided an environment that allowed us to scale the various parts of the infrastructure to deal with increased volumes of meter readings. By keying the raw reading stream by customer ID we could, if needed, scale the aggregation of individual customer profiles over multiple calculation nodes.&lt;/p&gt; &lt;p&gt;The complex task of deploying all of the various components was greatly simplified through the use of the Fabric8 Maven plugin, which allowed us to package up code, configuration, and Apache Kafka topic definitions into deployable units and deploy these directly into OpenShift with a single command.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F16%2Fsmart-meter-streams-kafka-openshift%2F&amp;#38;linkname=Smart-Meter%20Data%20Processing%20Using%20Apache%20Kafka%20on%20OpenShift" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F16%2Fsmart-meter-streams-kafka-openshift%2F&amp;#38;linkname=Smart-Meter%20Data%20Processing%20Using%20Apache%20Kafka%20on%20OpenShift" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F16%2Fsmart-meter-streams-kafka-openshift%2F&amp;#38;linkname=Smart-Meter%20Data%20Processing%20Using%20Apache%20Kafka%20on%20OpenShift" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F16%2Fsmart-meter-streams-kafka-openshift%2F&amp;#38;linkname=Smart-Meter%20Data%20Processing%20Using%20Apache%20Kafka%20on%20OpenShift" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F16%2Fsmart-meter-streams-kafka-openshift%2F&amp;#38;linkname=Smart-Meter%20Data%20Processing%20Using%20Apache%20Kafka%20on%20OpenShift" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F16%2Fsmart-meter-streams-kafka-openshift%2F&amp;#38;linkname=Smart-Meter%20Data%20Processing%20Using%20Apache%20Kafka%20on%20OpenShift" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F16%2Fsmart-meter-streams-kafka-openshift%2F&amp;#38;linkname=Smart-Meter%20Data%20Processing%20Using%20Apache%20Kafka%20on%20OpenShift" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F16%2Fsmart-meter-streams-kafka-openshift%2F&amp;#38;linkname=Smart-Meter%20Data%20Processing%20Using%20Apache%20Kafka%20on%20OpenShift" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F16%2Fsmart-meter-streams-kafka-openshift%2F&amp;#38;title=Smart-Meter%20Data%20Processing%20Using%20Apache%20Kafka%20on%20OpenShift" data-a2a-url="https://developers.redhat.com/blog/2018/07/16/smart-meter-streams-kafka-openshift/" data-a2a-title="Smart-Meter Data Processing Using Apache Kafka on OpenShift"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/07/16/smart-meter-streams-kafka-openshift/"&gt;Smart-Meter Data Processing Using Apache Kafka on OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/-PJfr6kKpKI" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;There is a major push in the United Kingdom to replace aging mechanical electricity meters with connected smart meters. New meters allow consumers to more closely monitor their energy usage and associated cost, and they enable the suppliers to automate the billing process because the meters automatically report fine-grained energy use. This post describes an architecture [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/07/16/smart-meter-streams-kafka-openshift/"&gt;Smart-Meter Data Processing Using Apache Kafka on OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/07/16/smart-meter-streams-kafka-openshift/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">506407</post-id><dc:creator>Hugo Hiden</dc:creator><dc:date>2018-07-16T11:00:44Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/07/16/smart-meter-streams-kafka-openshift/</feedburner:origLink></entry><entry><title>Infinispan 9.3.1.Final and 9.4.0.Alpha1</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/0aeZkHcEoQ8/infinispan-931final-and-940alpha1.html" /><category term="feed_group_name_infinispan" scheme="searchisko:content:tags" /><category term="feed_name_infinispan" scheme="searchisko:content:tags" /><author><name>Dan Berindei</name></author><id>searchisko:content:id:jbossorg_blog-infinispan_9_3_1_final_and_9_4_0_alpha1</id><updated>2018-07-16T09:41:40Z</updated><published>2018-07-16T09:41:00Z</published><content type="html">We have 2 new releases to announce today:&lt;br /&gt;&lt;br /&gt;&lt;b&gt;9.3.1.Final&lt;/b&gt; includes some important bug fixes, and we recommend all users of 9.3.0.Final to upgrade:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Fix for CVE-2018-1131 that allows unchecked deserialization in the server from binary java , XML and JSON payloads&lt;/li&gt;&lt;li&gt;Fixed transcoding from JSON/XML to java objects with deployed entities (&lt;a href="https://issues.jboss.org/browse/ISPN-9336"&gt;ISPN-9336&lt;/a&gt;)&lt;/li&gt;&lt;li&gt;Look up key in cache loader if the entry has expired but hasn't yet been removed from the data container (&lt;a href="https://issues.jboss.org/browse/ISPN-9370"&gt;ISPN-9370&lt;/a&gt;)&lt;/li&gt;&lt;li&gt;Avoid circular references in exceptions, as they were causing stack overflows with logback 1.2.x (&lt;a href="https://issues.jboss.org/browse/ISPN-9362"&gt;ISPN-9362&lt;/a&gt;) &lt;/li&gt;&lt;/ul&gt;See the full list of bug fixes &lt;a href="https://issues.jboss.org/secure/ReleaseNote.jspa?projectId=12310799&amp;amp;version=12338251"&gt;here&lt;/a&gt;.&amp;nbsp;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;9.4.0.Alpha1&lt;/b&gt; its the first iteration towards our next big release. Highlights include:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;The Spring Cache provider now supports two configuration properties with which you can determine how long to wait for read and write operations respectively (&lt;a href="https://issues.jboss.org/browse/ISPN-9301"&gt;ISPN-9301&lt;/a&gt;).&lt;/li&gt;&lt;li&gt;You can now obtain nanosecond-resolution statistics for average read/write/remove time (&lt;a href="https://issues.jboss.org/browse/ISPN-9352"&gt;ISPN-9352&lt;/a&gt;).&lt;/li&gt;&lt;li&gt;Queries now throw an AvailabilityException if the cache is in degraded mode and partition mode isn’t ALLOW_READ_WRITES ([&lt;a href="https://issues.jboss.org/browse/ISPN-9340"&gt;ISPN-9340&lt;/a&gt;)&lt;/li&gt;&lt;li&gt;Admin Console: You can now delete cache from Administration console (&lt;a href="https://issues.jboss.org/browse/ISPN-7291"&gt;ISPN-7291&lt;/a&gt;).&lt;/li&gt;&lt;li&gt;Following up on the segmented data container in 9.3.0.Final, cache stores can now be segmented as well, allowing for better performance for bulk operations (ie. &lt;span style="font-family: &amp;quot;Courier New&amp;quot;, Courier, monospace;"&gt;cache.size()&lt;/span&gt;, &lt;span style="font-family: &amp;quot;Courier New&amp;quot;, Courier, monospace;"&gt;cache.entrySet().stream()&lt;/span&gt;)&lt;/li&gt;&lt;li&gt;The server-side Hot Rod parser is now generated automatically (&lt;a href="https://issues.jboss.org/browse/ISPN-8981"&gt;ISPN-8981&lt;/a&gt;)&amp;nbsp; &lt;/li&gt;&lt;/ul&gt;The full list of 9.4.0.Alpha1 fixes is &lt;a href="https://issues.jboss.org/secure/ReleaseNote.jspa?projectId=12310799&amp;amp;version=12337824"&gt;here&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;You can find both releases on our &lt;a href="https://infinispan.org/download/" target="_blank"&gt;download page&lt;/a&gt;. Please report any issue&lt;span style="font-size: small;"&gt;s in our &lt;a href="https://issues.jboss.org/projects/ISPN"&gt;issue tracker&lt;/a&gt; and &lt;/span&gt;&lt;span style="font-size: small;"&gt;join the conversation in our &lt;a href="https://infinispan.zulipchat.com/" target="_blank"&gt;Zulip Chat&lt;/a&gt; to shape up our next release.&lt;/span&gt;&lt;br /&gt;&lt;span style="font-size: small;"&gt;&amp;nbsp;&lt;/span&gt; &lt;span style="font-size: small;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;/span&gt;&lt;/span&gt;&lt;img src="http://feeds.feedburner.com/~r/Infinispan/~4/DOUmfRw0nig" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/0aeZkHcEoQ8" height="1" width="1" alt=""/&gt;</content><summary>We have 2 new releases to announce today: 9.3.1.Final includes some important bug fixes, and we recommend all users of 9.3.0.Final to upgrade: Fix for CVE-2018-1131 that allows unchecked deserialization in the server from binary java , XML and JSON payloads Fixed transcoding from JSON/XML to java objects with deployed entities (ISPN-9336) Look up key in cache loader if the entry has expired but ha...</summary><dc:creator>Dan Berindei</dc:creator><dc:date>2018-07-16T09:41:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/Infinispan/~3/DOUmfRw0nig/infinispan-931final-and-940alpha1.html</feedburner:origLink></entry><entry><title>Maciej Swiderski is the new jBPM community lead</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/QrmKtejHDPk/maciej-swiderski-is-new-jbpm-community.html" /><category term="feed_group_name_jbpm" scheme="searchisko:content:tags" /><category term="feed_name_kverlaen" scheme="searchisko:content:tags" /><category term="jBPM" scheme="searchisko:content:tags" /><author><name>Kris Verlaenen</name></author><id>searchisko:content:id:jbossorg_blog-maciej_swiderski_is_the_new_jbpm_community_lead</id><updated>2018-07-13T12:56:57Z</updated><published>2018-07-13T12:56:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div style="text-align: justify;"&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;div style="margin-left: 1em; margin-right: 1em;"&gt;&lt;/div&gt;&lt;br /&gt;&lt;div style="-webkit-text-stroke-width: 0px; background-color: white; color: #222222; font-family: Arial, Helvetica, sans-serif; font-size: small; font-style: normal; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: 400; letter-spacing: normal; text-align: justify; text-decoration-color: initial; text-decoration-style: initial; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px;"&gt;&lt;div style="-webkit-text-stroke-width: 0px; background-color: white; color: #222222; font-family: Arial, Helvetica, sans-serif; font-size: small; font-style: normal; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: 400; letter-spacing: normal; text-decoration-color: initial; text-decoration-style: initial; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px;"&gt;I am very glad to be able to announce that Maciej (aka "Magic") Swiderski will officially become the new jBPM community lead.&lt;/div&gt;&lt;div style="-webkit-text-stroke-width: 0px; background-color: white; color: #222222; font-family: Arial, Helvetica, sans-serif; font-size: small; font-style: normal; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: 400; letter-spacing: normal; text-decoration-color: initial; text-decoration-style: initial; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="-webkit-text-stroke-width: 0px; background-color: white; color: #222222; font-family: Arial, Helvetica, sans-serif; font-size: small; font-style: normal; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: 400; letter-spacing: normal; text-decoration-color: initial; text-decoration-style: initial; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px;"&gt;Maciej is one of the most productive engineers I have ever known.&amp;nbsp; And while that has led to huge expectations whenever he starts working on something new, he somehow manages to constantly over-deliver anyway.&amp;nbsp; To be fair, I have to say "officially" as he's been doing the bulk of that work for a long time.&amp;nbsp; Everyone that ever interacted in the community no doubt knows him, and his blog might be even more famous, probably almost any customer question is answered in one of the numerous blogs he has written over the last few years.&amp;nbsp; I remember exchanging emails with him in 2010, the early days of jBPM 5, but he was even active in the community before that.&amp;nbsp; He joined full-time a few years later, and ever since has taken care of anything related to process execution for years.&amp;nbsp; Nowadays, he's involved in so much (from case management to our cloud story) and producing so much work that I saw no other solution than to just make him responsible for it ;-)&lt;/div&gt;&lt;div style="-webkit-text-stroke-width: 0px; background-color: white; color: #222222; font-family: Arial, Helvetica, sans-serif; font-size: small; font-style: normal; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: 400; letter-spacing: normal; text-decoration-color: initial; text-decoration-style: initial; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px;"&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://avatars3.githubusercontent.com/u/904474?s=460&amp;amp;v=4" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img alt="Afbeeldingsresultaat voor maciej swiderski" border="0" class="irc_mi" height="200" src="https://avatars3.githubusercontent.com/u/904474?s=460&amp;amp;v=4" style="margin-top: 94px;" width="200" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="-webkit-text-stroke-width: 0px; background-color: white; color: #222222; font-family: Arial, Helvetica, sans-serif; font-size: small; font-style: normal; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: 400; letter-spacing: normal; text-decoration-color: initial; text-decoration-style: initial; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px;"&gt;Well deserved, and long overdue !&amp;nbsp; Congratulations Maciej.&lt;br /&gt;&lt;br /&gt;PS: I'm not going anywhere in case anyone is wondering, still 100% involved, but given Maciej's continuous focus on the community and with the team growing this is the right move !&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/QrmKtejHDPk" height="1" width="1" alt=""/&gt;</content><summary>I am very glad to be able to announce that Maciej (aka "Magic") Swiderski will officially become the new jBPM community lead. Maciej is one of the most productive engineers I have ever known.  And while that has led to huge expectations whenever he starts working on something new, he somehow manages to constantly over-deliver anyway.  To be fair, I have to say "officially" as he's been doing the b...</summary><dc:creator>Kris Verlaenen</dc:creator><dc:date>2018-07-13T12:56:00Z</dc:date><feedburner:origLink>http://kverlaen.blogspot.com/2018/07/maciej-swiderski-is-new-jbpm-community.html</feedburner:origLink></entry><entry><title>This week in JBoss, 13th of July 2018 - Release It!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Vd5pMtqa094/this-week-in-jboss-13th-of-july-2018-release-it" /><category term="Apicurio" scheme="searchisko:content:tags" /><category term="Apiman" scheme="searchisko:content:tags" /><category term="byteman" scheme="searchisko:content:tags" /><category term="debezium" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_weeklyeditorial" scheme="searchisko:content:tags" /><category term="fuse;" scheme="searchisko:content:tags" /><category term="hibernate ogm" scheme="searchisko:content:tags" /><category term="hibernate-orm" scheme="searchisko:content:tags" /><category term="hibernate;" scheme="searchisko:content:tags" /><category term="infinispan;" scheme="searchisko:content:tags" /><category term="jbossts" scheme="searchisko:content:tags" /><category term="thorntail" scheme="searchisko:content:tags" /><category term="transactions" scheme="searchisko:content:tags" /><category term="wildfly swarm" scheme="searchisko:content:tags" /><author><name>Mark Little</name></author><id>searchisko:content:id:jbossorg_blog-this_week_in_jboss_13th_of_july_2018_release_it</id><updated>2018-07-13T12:08:13Z</updated><published>2018-07-13T12:08:00Z</published><content type="html">&lt;!-- [DocumentBodyStart:e1dfb38f-5751-40ad-b230-501ad5f99183] --&gt;&lt;div class="jive-rendered-content"&gt;&lt;p&gt;This editorial looks like it's going to be about release after release after release! The teams have really been busy!&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;First Marc has written a few articles about the new APIMan release (&lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/version_1_4_of_apiman_is_released" rel="nofollow"&gt;version 1.4&lt;/a&gt;) followed quickly by &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/version_1_4_3_of_apiman_is_released" rel="nofollow"&gt;1.4.3&lt;/a&gt; (if anyone finds 1.4.1 and 1.4.2 please return them to Marc care of JBoss!) He's also found the time to write about how you can &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/customising_path_patterns_for_your_apiman_gateway" rel="nofollow"&gt;customise your path patterns for the gateway&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;While we're at it, of course let's not forget about the equally interesting &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/hibernate_community_newsletter_12_2018" rel="nofollow"&gt;Hibernate Community Newsletter&lt;/a&gt;. And on the theme of Hibernate, Hibernate Search 5.10 has &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/second_maintenance_release_for_hibernate_search_5_10" rel="nofollow"&gt;another maintenance release&lt;/a&gt; and &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/hibernate_orm_5_1_15_final_released" rel="nofollow"&gt;Hibernate ORM 5.1.15.Final&lt;/a&gt; along with &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/hibernate_orm_5_3_2_final_released" rel="nofollow"&gt;ORM 5.3.2.Final&lt;/a&gt; were also released by the team, followed closely by &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/hibernate_ogm_5_4_0_beta2_release" rel="nofollow"&gt;OGM 5.4.0.Beta2&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Other releases over the period include &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/infinispan_9_3_0_final_is_out" rel="nofollow"&gt;Infinispan 9.3.0.Final&lt;/a&gt;, &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/announcing_thorntail_2_0_0_final" rel="nofollow"&gt;Thorntail 2.0.0.Final&lt;/a&gt;, a couple of &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/resteasy_3_6_0_final_and_4_0_0_beta4" rel="nofollow"&gt;RESTeasy releases&lt;/a&gt;, &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/byteman_4_0_3_has_been_released" rel="nofollow"&gt;ByteMan 4.0.3&lt;/a&gt;, the ever popular Debezium &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/debezium_0_8_0_cr1_is_released" rel="nofollow"&gt;had a release&lt;/a&gt;, &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/apache_camel_2_22_released_with_spring_boot_2_support" rel="nofollow"&gt;Apache Camel 2.22&lt;/a&gt; came out, and &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/keycloak_4_1_0_final_released" rel="nofollow"&gt;Keycloak 4.1.0.Final&lt;/a&gt; (check out this article around &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/keycloak_on_kubernetes" rel="nofollow"&gt;Keycloak on Kubernetes&lt;/a&gt; too!)&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Not quite a release but definitely newsworthy, &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/mario_fusco_is_the_new_drools_project_lead" rel="nofollow"&gt;Mario Fusco is the new Drools lead&lt;/a&gt;! Well done Mario!!&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Chritina Lin has written a &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/fuse_contract_first_api_design_with_apicurio_and_fuse_camel_part_one" rel="nofollow"&gt;great first article&lt;/a&gt; on contract first design with Apicurio and Fuse.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Let's wrap up with a personal favourite: the JBossTS team have done some interesting work around the LRCO optimisation and you can read about it in &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/narayana_commit_markable_resource_a_faultless_lrco_for_jdbc_datasources" rel="nofollow"&gt;this article&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;OK that's it for now. Enjoy!&lt;/p&gt;&lt;/div&gt;&lt;!-- [DocumentBodyEnd:e1dfb38f-5751-40ad-b230-501ad5f99183] --&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Vd5pMtqa094" height="1" width="1" alt=""/&gt;</content><summary>This editorial looks like it's going to be about release after release after release! The teams have really been busy!   First Marc has written a few articles about the new APIMan release (version 1.4) followed quickly by 1.4.3 (if anyone finds 1.4.1 and 1.4.2 please return them to Marc care of JBoss!) He's also found the time to write about how you can customise your path patterns for the gateway...</summary><dc:creator>Mark Little</dc:creator><dc:date>2018-07-13T12:08:00Z</dc:date><feedburner:origLink>https://developer.jboss.org/blogs/weekly-editorial/2018/07/13/this-week-in-jboss-13th-of-july-2018-release-it</feedburner:origLink></entry><entry><title>Contract-First API Design with Apicurio and Red Hat Fuse/Camel</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/C5nm9tnzf08/" /><category term="JBoss Fuse" /><category term="Modern App Dev" /><category term="Red Hat OpenShift Container Platform" /><category term="Agile Integration" /><category term="apache camel" /><category term="API" /><category term="Apicurio" /><category term="camel" /><category term="contract first design" /><category term="microservices" /><category term="OpenAPI" /><category term="Red Hat Fuse" /><author><name>Christina Lin</name></author><id>https://developers.redhat.com/blog/?p=505057</id><updated>2018-07-12T16:00:52Z</updated><published>2018-07-12T16:00:52Z</published><content type="html">&lt;p&gt;This is part one of my two-article series that demonstrates how to implement contract-first API design using &lt;a href="https://www.apicur.io/"&gt;Apicurio&lt;/a&gt; and &lt;a href="https://www.redhat.com/en/technologies/jboss-middleware/fuse"&gt;Red Hat Fuse&lt;/a&gt;.  It covers how to create an OpenAPI standard document as the contract between API providers and consumers using Apicurio Studio. It also shows how to quickly create mock tests using &lt;a href="https://developers.redhat.com/products/fuse/overview/"&gt;Red Hat Fuse&lt;/a&gt; which is based on Camel.&lt;/p&gt; &lt;p&gt;There are two common approaches when it comes to creating APIs:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Code first (top-down)&lt;/li&gt; &lt;li&gt;Contract first (bottom-up)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;span id="more-505057"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Code-First Approach&lt;/h2&gt; &lt;p&gt;To ESB developers, these two approaches aren&amp;#8217;t new. Before, it was the WSDL that defined the contract of the service. We were doing a lot more coding first, because it&amp;#8217;s easy to write a couple of Java classes and generate the WSDL for the consumers. This is the &lt;em&gt;code-first&lt;/em&gt; approach, which has been the most common in the past.&lt;/p&gt; &lt;div class="separator"&gt;&lt;a href="https://4.bp.blogspot.com/-xn1vGjSAAnE/WzqGGNtRwcI/AAAAAAAAFkw/5QNFPyU4AJ4-8S8X8xjwHLL4aEjfA_B3QCLcBGAs/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B4.07.01%2BAM.png"&gt;&lt;img class="aligncenter" src="https://4.bp.blogspot.com/-xn1vGjSAAnE/WzqGGNtRwcI/AAAAAAAAFkw/5QNFPyU4AJ4-8S8X8xjwHLL4aEjfA_B3QCLcBGAs/s400/Screen%2BShot%2B2018-07-03%2Bat%2B4.07.01%2BAM.png" width="400" height="270" border="0" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;p&gt;Code-first development can be pretty straightforward if the consumer of your application has decided how they want the service to work. There is always a preliminary discussion between the developer and consumer about the data to be exchanged. It is likely that there is some notion of the &amp;#8220;contract&amp;#8221; for the service, but often it is implicit. With this approach small changes are inevitable, and it takes a toll on the developer to grind through the long process of making all these updates and getting everything right. Since the contract isn&amp;#8217;t explicitly spelled out, these changes might actually break things because the developer and the consumer each have different understanding of the service&amp;#8217;s intended operation.&lt;/p&gt; &lt;p&gt;.&lt;/p&gt; &lt;h2&gt;Contract-First Approach&lt;/h2&gt; &lt;p&gt;Business users and citizen users/developers can use the new OpenAPI specification to negotiate and perhaps perform a couple of pre-tests with the consumer before the design gets handed over to the developer. This design approach is called &lt;em&gt;contract first&lt;/em&gt;. It has become more and more popular because it prevents the developer from wasting time while negotiating how the service should be provided.&lt;/p&gt; &lt;div class="separator"&gt;&lt;a href="https://1.bp.blogspot.com/-yveltlUuzW4/WzqLuvxMhrI/AAAAAAAAFk8/SbjUNBZ3udIGlMkTSlITPhSqKUT3N6AHgCLcBGAs/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B4.31.35%2BAM.png"&gt;&lt;img class="aligncenter" src="https://1.bp.blogspot.com/-yveltlUuzW4/WzqLuvxMhrI/AAAAAAAAFk8/SbjUNBZ3udIGlMkTSlITPhSqKUT3N6AHgCLcBGAs/s400/Screen%2BShot%2B2018-07-03%2Bat%2B4.31.35%2BAM.png" width="400" height="222" border="0" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;p&gt;Obviously, there are many ways to implement a contract-first API. I am going to demonstrate how it can be done using Apicurio and Red Hat Fuse. I will be using Apicurio to define APIs and automatically generate the Red Hat Fuse project for the purpose of quick testing.&lt;/p&gt; &lt;h2&gt;Creating a Customer Service API&lt;/h2&gt; &lt;p&gt;In this example demo, we will be providing customer info to our consumer as a service. For the sake of this demo, we will start by retrieving and creating a customer service.&lt;/p&gt; &lt;div class="separator"&gt;&lt;a href="http://1.bp.blogspot.com/-XTDagvBT42k/Wztx7K9XbJI/AAAAAAAAFlM/JqqlHpz7vXA2rKSZZz5eOckSRnVq7NnWACK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B8.03.27%2BAM.png"&gt;&lt;img src="https://1.bp.blogspot.com/-XTDagvBT42k/Wztx7K9XbJI/AAAAAAAAFlM/JqqlHpz7vXA2rKSZZz5eOckSRnVq7NnWACK4BGAYYCw/s400/Screen%2BShot%2B2018-07-03%2Bat%2B8.03.27%2BAM.png" width="400" height="196" border="0" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;h3&gt;Defining the Application with the OpenAPI Specification in Apicurio&lt;/h3&gt; &lt;p&gt;Apicurio is a web-based open source tool for designing APIs that are based on the OpenAPI specification.&lt;/p&gt; &lt;p&gt;If you don&amp;#8217;t already have an Apicurio account, you need to first register for one.&lt;/p&gt; &lt;div class="separator"&gt;&lt;a href="http://1.bp.blogspot.com/-ChQnfK46nzg/WztygyxYt2I/AAAAAAAAFlY/HU51E1gVIqoI1M2OhSgj30wRDV4SsU0BACK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B8.03.42%2BAM.png"&gt;&lt;img src="https://1.bp.blogspot.com/-ChQnfK46nzg/WztygyxYt2I/AAAAAAAAFlY/HU51E1gVIqoI1M2OhSgj30wRDV4SsU0BACK4BGAYYCw/s640/Screen%2BShot%2B2018-07-03%2Bat%2B8.03.42%2BAM.png" width="640" height="192" border="0" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;p&gt;After registering, you will be redirected to the main screen of Apicurio.&lt;b&gt; &lt;/b&gt;Then, after discussing with the consumer what they wish to have for the customer service, you can start creating the contract by clicking &lt;b&gt;Create New API&lt;/b&gt;.&lt;br /&gt; &lt;b&gt;&lt;br /&gt; &lt;/b&gt;&lt;a href="http://2.bp.blogspot.com/-PwRajchevj0/WztyzBw4vQI/AAAAAAAAFlk/YafjXYkrJL0t46mWjImoox8IoAe37u2zACK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B8.06.13%2BAM.png"&gt;&lt;img src="https://2.bp.blogspot.com/-PwRajchevj0/WztyzBw4vQI/AAAAAAAAFlk/YafjXYkrJL0t46mWjImoox8IoAe37u2zACK4BGAYYCw/s640/Screen%2BShot%2B2018-07-03%2Bat%2B8.06.13%2BAM.png" width="640" height="332" border="0" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;What you need to do next is pretty simple:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Create the API (service).&lt;/li&gt; &lt;li&gt;Create the data definitions (if any are required).&lt;/li&gt; &lt;li&gt;Add paths; define parameters and operations; and return responses to the paths.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Enter the name of the service, and it would be nice to add a description for the service so it&amp;#8217;s easier for people to understand what every path means.&lt;/p&gt; &lt;p&gt;&lt;a href="http://1.bp.blogspot.com/-nYGSbZRAjac/WzuWDhWRC8I/AAAAAAAAFpI/jzK4uncQ8FgXzCIj-K9Dc3oBgIhb8pRNgCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B11.27.59%2BAM.png"&gt;&lt;img src="https://1.bp.blogspot.com/-nYGSbZRAjac/WzuWDhWRC8I/AAAAAAAAFpI/jzK4uncQ8FgXzCIj-K9Dc3oBgIhb8pRNgCK4BGAYYCw/s640/Screen%2BShot%2B2018-07-03%2Bat%2B11.27.59%2BAM.png" width="640" height="158" border="0" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;div&gt;Enter a customer definition to show info about what we are going exchange.&lt;/div&gt; &lt;p&gt;&lt;a href="http://3.bp.blogspot.com/-lYJT8fTF56E/Wzt220wWDjI/AAAAAAAAFmI/26TUka6CyPcZfen6tCUQX-Zu1zVuC911gCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B8.11.25%2BAM.png"&gt;&lt;img src="https://3.bp.blogspot.com/-lYJT8fTF56E/Wzt220wWDjI/AAAAAAAAFmI/26TUka6CyPcZfen6tCUQX-Zu1zVuC911gCK4BGAYYCw/s640/Screen%2BShot%2B2018-07-03%2Bat%2B8.11.25%2BAM.png" width="640" height="216" border="0" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Add and define the properties and their data type.&lt;/p&gt; &lt;div class="separator"&gt;&lt;a href="http://1.bp.blogspot.com/-abCM_73sxto/Wzt4Kg7FnpI/AAAAAAAAFmU/qJbyWPUwf2sZKQfTYjPuI8p1aqXDGo3iwCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B8.24.36%2BAM.png"&gt;&lt;img src="https://1.bp.blogspot.com/-abCM_73sxto/Wzt4Kg7FnpI/AAAAAAAAFmU/qJbyWPUwf2sZKQfTYjPuI8p1aqXDGo3iwCK4BGAYYCw/s640/Screen%2BShot%2B2018-07-03%2Bat%2B8.24.36%2BAM.png" width="640" height="178" border="0" /&gt;&lt;/a&gt;&lt;a href="http://4.bp.blogspot.com/-7KqBiY8QYP0/Wzt4MKqqdnI/AAAAAAAAFmc/78f-wIvgAuALhj2g5aFMyQ4gs0b02SE4QCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B8.27.54%2BAM.png"&gt;&lt;img src="https://4.bp.blogspot.com/-7KqBiY8QYP0/Wzt4MKqqdnI/AAAAAAAAFmc/78f-wIvgAuALhj2g5aFMyQ4gs0b02SE4QCK4BGAYYCw/s400/Screen%2BShot%2B2018-07-03%2Bat%2B8.27.54%2BAM.png" width="400" height="251" border="0" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;div class="separator"&gt;&lt;/div&gt; &lt;div&gt;&lt;/div&gt; &lt;div class=""&gt;Then you can start adding the paths to the document.&lt;/div&gt; &lt;div&gt;&lt;/div&gt; &lt;div&gt;&lt;/div&gt; &lt;div class="separator"&gt;&lt;a href="http://4.bp.blogspot.com/-swa98cIRZzs/Wzt_DIkuxMI/AAAAAAAAFms/0TjvMT6wqTI62IOrL8PayzaE9zFE3aMDQCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B8.07.43%2BAM.png"&gt;&lt;img src="https://4.bp.blogspot.com/-swa98cIRZzs/Wzt_DIkuxMI/AAAAAAAAFms/0TjvMT6wqTI62IOrL8PayzaE9zFE3aMDQCK4BGAYYCw/s640/Screen%2BShot%2B2018-07-03%2Bat%2B8.07.43%2BAM.png" width="640" height="170" border="0" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;div class="separator"&gt;&lt;/div&gt; &lt;div&gt;&lt;/div&gt; &lt;div class="separator"&gt;Add parameters and define their type.&lt;/div&gt; &lt;div&gt;&lt;/div&gt; &lt;div class="separator"&gt;&lt;/div&gt; &lt;div class="separator"&gt;&lt;a href="http://4.bp.blogspot.com/-OZ3nXxrFT6I/Wzt_PNEi4HI/AAAAAAAAFm0/AoMy4DeX7ec9PmkurBta2zzT-M7b4qIBwCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B8.28.04%2BAM.png"&gt;&lt;img src="https://4.bp.blogspot.com/-OZ3nXxrFT6I/Wzt_PNEi4HI/AAAAAAAAFm0/AoMy4DeX7ec9PmkurBta2zzT-M7b4qIBwCK4BGAYYCw/s640/Screen%2BShot%2B2018-07-03%2Bat%2B8.28.04%2BAM.png" width="640" height="240" border="0" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;div class="separator"&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="http://1.bp.blogspot.com/-2x-JSSeBHj0/Wzt_mgy1fXI/AAAAAAAAFnE/B7PsCRbU3487BaAP6RnzfRJbPEgTSOHNgCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B8.28.50%2BAM.png"&gt;&lt;img src="https://1.bp.blogspot.com/-2x-JSSeBHj0/Wzt_mgy1fXI/AAAAAAAAFnE/B7PsCRbU3487BaAP6RnzfRJbPEgTSOHNgCK4BGAYYCw/s640/Screen%2BShot%2B2018-07-03%2Bat%2B8.28.50%2BAM.png" width="640" height="402" border="0" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="http://4.bp.blogspot.com/-UaS3tO6kqpQ/Wzt_nSLFVHI/AAAAAAAAFnM/2p3CJNQpDRM7c6qHk0noKfcBgTj19F2hQCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B8.28.58%2BAM.png"&gt;&lt;img src="https://4.bp.blogspot.com/-UaS3tO6kqpQ/Wzt_nSLFVHI/AAAAAAAAFnM/2p3CJNQpDRM7c6qHk0noKfcBgTj19F2hQCK4BGAYYCw/s640/Screen%2BShot%2B2018-07-03%2Bat%2B8.28.58%2BAM.png" width="640" height="236" border="0" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="http://3.bp.blogspot.com/-nj6qZhw1GBo/Wzt_tsuHMeI/AAAAAAAAFnU/3ZGagdOEu9Q50qJaxU1QFrKgpCLeX4kxwCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B8.29.21%2BAM.png"&gt;&lt;img src="https://3.bp.blogspot.com/-nj6qZhw1GBo/Wzt_tsuHMeI/AAAAAAAAFnU/3ZGagdOEu9Q50qJaxU1QFrKgpCLeX4kxwCK4BGAYYCw/s640/Screen%2BShot%2B2018-07-03%2Bat%2B8.29.21%2BAM.png" width="640" height="136" border="0" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Add responses, too (if your path needs them).&lt;/p&gt; &lt;p&gt;&lt;a href="http://1.bp.blogspot.com/-QmmJKkRFnqg/WzuCYXCyjoI/AAAAAAAAFno/bw8o469bwoMuZ07ey1GyZs1r1XGzJEsZQCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B8.36.37%2BAM.png"&gt;&lt;img src="https://1.bp.blogspot.com/-QmmJKkRFnqg/WzuCYXCyjoI/AAAAAAAAFno/bw8o469bwoMuZ07ey1GyZs1r1XGzJEsZQCK4BGAYYCw/s640/Screen%2BShot%2B2018-07-03%2Bat%2B8.36.37%2BAM.png" width="640" height="408" border="0" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Once you are done, it&amp;#8217;s time to export the API standard document.&lt;/p&gt; &lt;p&gt;&lt;a href="http://4.bp.blogspot.com/-XDM2UyK6Bsk/WzuDBZjtgwI/AAAAAAAAFn0/Ks_HsobFs1EIXRTblCpKXGW0vthr90jhQCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B8.43.13%2BAM.png"&gt;&lt;img src="https://4.bp.blogspot.com/-XDM2UyK6Bsk/WzuDBZjtgwI/AAAAAAAAFn0/Ks_HsobFs1EIXRTblCpKXGW0vthr90jhQCK4BGAYYCw/s640/Screen%2BShot%2B2018-07-03%2Bat%2B8.43.13%2BAM.png" width="640" height="292" border="0" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h3&gt;&lt;b&gt;Generating the Red Hat Fuse Project from the Standard API Document&lt;/b&gt;&lt;/h3&gt; &lt;p&gt;Go to Red Hat Developer Studio and create a new Red Hat Fuse project by right-clicking in the navigation panel and selecting &lt;strong&gt;New-&amp;#62;Fuse Integration Project&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;&lt;a href="http://4.bp.blogspot.com/-WJPxKJf_8sQ/WzuDXnvgfNI/AAAAAAAAFoI/v5x9AxjkvO0OMc-q_fF1CeW2cBW5IWNIwCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B10.08.18%2BAM.png"&gt;&lt;img src="https://4.bp.blogspot.com/-WJPxKJf_8sQ/WzuDXnvgfNI/AAAAAAAAFoI/v5x9AxjkvO0OMc-q_fF1CeW2cBW5IWNIwCK4BGAYYCw/s640/Screen%2BShot%2B2018-07-03%2Bat%2B10.08.18%2BAM.png" width="640" height="224" border="0" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Provide a name for the project.&lt;/p&gt; &lt;div&gt;&lt;a href="http://1.bp.blogspot.com/-H3aeymLiXIk/WzuDQ6MwfrI/AAAAAAAAFn8/W0u6VQx5AWg8_NPsVMYNwpeh5xZ72NEvQCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B8.51.36%2BAM.png"&gt;&lt;img src="https://1.bp.blogspot.com/-H3aeymLiXIk/WzuDQ6MwfrI/AAAAAAAAFn8/W0u6VQx5AWg8_NPsVMYNwpeh5xZ72NEvQCK4BGAYYCw/s320/Screen%2BShot%2B2018-07-03%2Bat%2B8.51.36%2BAM.png" width="320" height="212" border="0" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;p&gt;We are going to use a microservices approach, so select the most-popular runtime—Spring Boot. We will be running this on the Red Hat OpenShift cloud platform.&lt;/p&gt; &lt;div&gt;&lt;a href="http://4.bp.blogspot.com/-FG9ynb0VjVg/WzuEF0ADebI/AAAAAAAAFoY/si2x1omk0pwJFHXz2z39ipS3FHMMV1EbwCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B8.51.45%2BAM.png"&gt;&lt;img src="https://4.bp.blogspot.com/-FG9ynb0VjVg/WzuEF0ADebI/AAAAAAAAFoY/si2x1omk0pwJFHXz2z39ipS3FHMMV1EbwCK4BGAYYCw/s400/Screen%2BShot%2B2018-07-03%2Bat%2B8.51.45%2BAM.png" width="356" height="400" border="0" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;p&gt;Select the Spring DSL template.&lt;/p&gt; &lt;div&gt;&lt;a href="http://1.bp.blogspot.com/-wy1LtMUGz7Y/WzuEaVaCtWI/AAAAAAAAFok/Y6g8jJ3aJEs2rq7uifgEyKOPnxC6N3c5QCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B8.51.59%2BAM.png"&gt;&lt;img src="https://1.bp.blogspot.com/-wy1LtMUGz7Y/WzuEaVaCtWI/AAAAAAAAFok/Y6g8jJ3aJEs2rq7uifgEyKOPnxC6N3c5QCK4BGAYYCw/s400/Screen%2BShot%2B2018-07-03%2Bat%2B8.51.59%2BAM.png" width="360" height="400" border="0" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;p&gt;You will then have a sample Red Hat Fuse project:&lt;/p&gt; &lt;p&gt;&lt;a href="http://2.bp.blogspot.com/-8yKi5i3kJdw/WzuFrH9Y0lI/AAAAAAAAFow/AVHm18CKbkIELG0mL3uSLCnzJOMF_EsgQCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B10.17.38%2BAM.png"&gt;&lt;img src="https://2.bp.blogspot.com/-8yKi5i3kJdw/WzuFrH9Y0lI/AAAAAAAAFow/AVHm18CKbkIELG0mL3uSLCnzJOMF_EsgQCK4BGAYYCw/s640/Screen%2BShot%2B2018-07-03%2Bat%2B10.17.38%2BAM.png" width="640" height="144" border="0" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Add the generated API specification document to the directory &lt;code&gt;src/spec/&lt;/code&gt;.&lt;/p&gt; &lt;div class="separator"&gt;&lt;a href="http://3.bp.blogspot.com/-gNgkWcdI64c/WzuNhvUnKmI/AAAAAAAAFo8/kmW2PwCHAg8sjlnNwQvvKgbxZ7dsiUqMACK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B10.50.43%2BAM.png"&gt;&lt;img src="https://3.bp.blogspot.com/-gNgkWcdI64c/WzuNhvUnKmI/AAAAAAAAFo8/kmW2PwCHAg8sjlnNwQvvKgbxZ7dsiUqMACK4BGAYYCw/s320/Screen%2BShot%2B2018-07-03%2Bat%2B10.50.43%2BAM.png" width="320" height="277" border="0" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;p&gt;Edit the &lt;code&gt;pom.xml&lt;/code&gt; file, and add the following to it:&lt;/p&gt; &lt;pre&gt;&amp;#60;plugins&amp;#62; .... &amp;#60;plugin&amp;#62;   &amp;#60;groupId&amp;#62;org.apache.camel&amp;#60;/groupId&amp;#62;   &amp;#60;artifactId&amp;#62;camel-restdsl-swagger-plugin&amp;#60;/artifactId&amp;#62;   &amp;#60;version&amp;#62;2.21.0&amp;#60;/version&amp;#62;   &amp;#60;configuration&amp;#62;     &amp;#60;specificationUri&amp;#62;src/spec/MyCustomer.json&amp;#60;/specificationUri&amp;#62;     &amp;#60;fileName&amp;#62;camel-rest.xml&amp;#60;/fileName&amp;#62;     &amp;#60;outputDirectory&amp;#62;src/main/resources/spring&amp;#60;/outputDirectory&amp;#62;       &amp;#60;/configuration&amp;#62; &amp;#60;/plugin&amp;#62; .... &amp;#60;/plugin&amp;#62; &lt;/pre&gt; &lt;p&gt;Generate the XML by running the following in the command-line tool: &lt;b&gt;  &lt;/b&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;mvn camel-restdsl-swagger:generate-xml&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="http://3.bp.blogspot.com/-aqD9wgB3KFE/WzuW2nHTU1I/AAAAAAAAFpU/HOO-xkHd89QeWNkBD2kaBjuLMbUCv9ZRQCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B11.31.08%2BAM.png"&gt;&lt;img src="https://3.bp.blogspot.com/-aqD9wgB3KFE/WzuW2nHTU1I/AAAAAAAAFpU/HOO-xkHd89QeWNkBD2kaBjuLMbUCv9ZRQCK4BGAYYCw/s640/Screen%2BShot%2B2018-07-03%2Bat%2B11.31.08%2BAM.png" width="640" height="190" border="0" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;You will then find a newly generated Camel context named &lt;code&gt;camel-rest.xml&lt;/code&gt;, which has all the path implementations in Camel.&lt;/p&gt; &lt;p&gt;&lt;a href="http://2.bp.blogspot.com/-ZHrnbN0ukGs/WzuYTa0XpxI/AAAAAAAAFps/sAGdtJQUmDgbyJ4Nb8Zzp30F6UJ5jFcpACK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B11.33.36%2BAM.png"&gt;&lt;img src="https://2.bp.blogspot.com/-ZHrnbN0ukGs/WzuYTa0XpxI/AAAAAAAAFps/sAGdtJQUmDgbyJ4Nb8Zzp30F6UJ5jFcpACK4BGAYYCw/s640/Screen%2BShot%2B2018-07-03%2Bat%2B11.33.36%2BAM.png" width="640" height="206" border="0" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;From that file, copy everything inside the &lt;code&gt;&amp;#60;rests&amp;#62;&lt;/code&gt; tags and paste it into the original &lt;code&gt;camel-context.xml&lt;/code&gt; file inside &lt;code&gt;camelContext&lt;/code&gt;. Add the following rest configuration on top of the rest block.&lt;/p&gt; &lt;pre&gt;&amp;#60;restConfiguration apiContextPath="api-docs" bindingMode="auto"             component="undertow" contextPath="/customer"             enableCORS="true" port="8080"&amp;#62;    &amp;#60;apiProperty key="cors" value="true"/&amp;#62;    &amp;#60;apiProperty key="api.title" value="Customer Service"/&amp;#62;    &amp;#60;apiProperty key="api.version" value="1.0.0"/&amp;#62; &amp;#60;/restConfiguration&amp;#62;&lt;/pre&gt; &lt;div&gt;&lt;/div&gt; &lt;div&gt;&lt;/div&gt; &lt;div&gt;&lt;/div&gt; &lt;div&gt;&lt;a href="http://3.bp.blogspot.com/-TcwfnhhYf_Y/WzufhZBQE5I/AAAAAAAAFp4/gJ25mM5u_5QW1qKOpiWQddOuh1daxuVIwCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-03%2Bat%2B12.07.58%2BPM.png"&gt;&lt;img src="https://3.bp.blogspot.com/-TcwfnhhYf_Y/WzufhZBQE5I/AAAAAAAAFp4/gJ25mM5u_5QW1qKOpiWQddOuh1daxuVIwCK4BGAYYCw/s640/Screen%2BShot%2B2018-07-03%2Bat%2B12.07.58%2BPM.png" width="640" height="222" border="0" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;div&gt;&lt;/div&gt; &lt;div&gt;&lt;/div&gt; &lt;div&gt;&lt;/div&gt; &lt;div&gt;&lt;/div&gt; &lt;div&gt;Delete the generated &lt;code&gt;camel-rest.xml&lt;/code&gt; file.&lt;/div&gt; &lt;h3&gt;Mocking the APIs with Apache Camel&lt;/h3&gt; &lt;p&gt;We will mock the returned result by adding a constant, defined bean in the Camel context.&lt;/p&gt; &lt;p&gt;To do that, in the &lt;code&gt;src/main.resource/spring&lt;/code&gt; folder, add a &lt;code&gt;beans.xml&lt;/code&gt;&lt;b&gt; &lt;/b&gt;file&lt;b&gt; &lt;/b&gt;by right-clicking the folder and selecting &lt;strong&gt;New-&amp;#62;beans.xml File&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;&lt;a href="http://2.bp.blogspot.com/-Og8GmwF5Ri8/Wz4sotd7_nI/AAAAAAAAFqI/ZJA_QTS96-0QuhKo0iLClYb4YdL87On7wCK4BGAYYCw/s1600/Screen%2BShot%2B2018-07-05%2Bat%2B10.34.50%2BAM.png"&gt;&lt;img src="https://2.bp.blogspot.com/-Og8GmwF5Ri8/Wz4sotd7_nI/AAAAAAAAFqI/ZJA_QTS96-0QuhKo0iLClYb4YdL87On7wCK4BGAYYCw/s640/Screen%2BShot%2B2018-07-05%2Bat%2B10.34.50%2BAM.png" width="640" height="346" border="0" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Insert the following code snippet to the &lt;code&gt;beans.xml&lt;/code&gt; file:&lt;/p&gt; &lt;pre&gt;&amp;#60;util:list id="CustomerList" list-class="java.util.ArrayList"&amp;#62;    &amp;#60;ref bean="Customer"/&amp;#62; &amp;#60;/util:list&amp;#62; &amp;#60;util:map id="Customer" map-class="java.util.HashMap"&amp;#62;    &amp;#60;entry key="name" value="Christina"/&amp;#62;    &amp;#60;entry key="age" value="28"/&amp;#62;    &amp;#60;entry key="contact" value="765483921"/&amp;#62; &amp;#60;/util:map&amp;#62; &lt;/pre&gt; &lt;p&gt;Add the Camel routes to the &lt;code&gt;camel-context.xml&lt;/code&gt; file. The first one returns mock customer data, and the second one takes customer info as input.&lt;/p&gt; &lt;pre&gt;&amp;#60;route id="rest1-route"&amp;#62;  &amp;#60;from id="restone" uri="direct:rest1"/&amp;#62;   &amp;#60;setBody id="route-setBody1"&amp;#62;     &amp;#60;simple&amp;#62;bean:CustomerList?method=get(0)&amp;#60;/simple&amp;#62;   &amp;#60;/setBody&amp;#62; &amp;#60;/route&amp;#62; &amp;#60;route id="rest2-route"&amp;#62;   &amp;#60;from id="resttwo" uri="direct:rest2"/&amp;#62;   &amp;#60;log id="input-log" message="&amp;#62;&amp;#62;&amp;#62; ${body}"/&amp;#62;     &amp;#60;setBody id="route-setBody2"&amp;#62;       &amp;#60;simple&amp;#62;Customer created&amp;#60;/simple&amp;#62;     &amp;#60;/setBody&amp;#62; &amp;#60;/route&amp;#62;&lt;/pre&gt; &lt;p&gt;Now, it&amp;#8217;s time to set up the dependency libraries in the &lt;code&gt;pom.xml&lt;/code&gt; file:&lt;/p&gt; &lt;pre&gt;&amp;#60;dependency&amp;#62;   &amp;#60;groupId&amp;#62;org.springframework.boot&amp;#60;/groupId&amp;#62;   &amp;#60;artifactId&amp;#62;spring-boot-starter-undertow&amp;#60;/artifactId&amp;#62; &amp;#60;/dependency&amp;#62; &amp;#60;dependency&amp;#62;   &amp;#60;groupId&amp;#62;org.apache.camel&amp;#60;/groupId&amp;#62;   &amp;#60;artifactId&amp;#62;camel-undertow-starter&amp;#60;/artifactId&amp;#62; &amp;#60;/dependency&amp;#62;  &amp;#60;dependency&amp;#62;   &amp;#60;groupId&amp;#62;org.apache.camel&amp;#60;/groupId&amp;#62;   &amp;#60;artifactId&amp;#62;camel-jackson-starter&amp;#60;/artifactId&amp;#62; &amp;#60;/dependency&amp;#62;  &amp;#60;dependency&amp;#62;   &amp;#60;groupId&amp;#62;org.apache.camel&amp;#60;/groupId&amp;#62;   &amp;#60;artifactId&amp;#62;camel-swagger-java-starter&amp;#60;/artifactId&amp;#62; &amp;#60;/dependency&amp;#62; &lt;/pre&gt; &lt;div&gt;Finally, it&amp;#8217;s time to test by running the following at the command line:&lt;/div&gt; &lt;p&gt;&lt;code&gt;mvn sprint-boot:run&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Two endpoints will be exposed for testing:&lt;/p&gt; &lt;pre&gt;Christina Laptop$ curl http://YOURIP:8080/customer/id/123 {"name":"Christina","age":"28","contact":"765483921"} Christina Laptop$ curl --header "Content-Type: application/json"   --request PUT   --data '{"name":"Christina","age":28,"contact":"765483921"}'   http://YOURIP:8080/customer/add "Customer created" &lt;/pre&gt; &lt;p&gt;You are now ready for the consumer to start testing the APIs.&lt;/p&gt; &lt;p&gt;In the next article in this series, I will take you through how to actually implement the API, expose it in the cloud, and manage it.&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;For more information see these Red Hat Developer resources:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;[DevNation Live] &amp;#8211; &lt;a href="https://developers.redhat.com/videos/youtube/zuEYtMvHN6g/"&gt;Camel Riders in the Cloud&lt;/a&gt; &amp;#8211; Watch the recording of Claus Ibsen,  author of the Camel in Action books.&lt;/li&gt; &lt;li&gt;Download the free ebook &amp;#8211; &lt;a href="https://developers.redhat.com/books/selections-camel-action/"&gt;Selections from Camel in Action, 2nd edition&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Learn more about &lt;a href="https://developers.redhat.com/products/fuse/overview/"&gt;Red Hat Fuse&lt;/a&gt; &amp;#8211; a distributed, cloud-native integration solution that is based on Camel&lt;/li&gt; &lt;li&gt;Read &lt;a href="https://developers.redhat.com/blog/2018/04/11/api-journey-idea-deployment-agile-part1/"&gt;An API Journey: From idea to deployment the Agile Way &amp;#8211; Part 1&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F12%2Fcontract-first-api-design-with-apicurio-and-red-hat-fuse%2F&amp;#38;linkname=Contract-First%20API%20Design%20with%20Apicurio%20and%20Red%20Hat%20Fuse%2FCamel" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F12%2Fcontract-first-api-design-with-apicurio-and-red-hat-fuse%2F&amp;#38;linkname=Contract-First%20API%20Design%20with%20Apicurio%20and%20Red%20Hat%20Fuse%2FCamel" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F12%2Fcontract-first-api-design-with-apicurio-and-red-hat-fuse%2F&amp;#38;linkname=Contract-First%20API%20Design%20with%20Apicurio%20and%20Red%20Hat%20Fuse%2FCamel" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F12%2Fcontract-first-api-design-with-apicurio-and-red-hat-fuse%2F&amp;#38;linkname=Contract-First%20API%20Design%20with%20Apicurio%20and%20Red%20Hat%20Fuse%2FCamel" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F12%2Fcontract-first-api-design-with-apicurio-and-red-hat-fuse%2F&amp;#38;linkname=Contract-First%20API%20Design%20with%20Apicurio%20and%20Red%20Hat%20Fuse%2FCamel" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F12%2Fcontract-first-api-design-with-apicurio-and-red-hat-fuse%2F&amp;#38;linkname=Contract-First%20API%20Design%20with%20Apicurio%20and%20Red%20Hat%20Fuse%2FCamel" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F12%2Fcontract-first-api-design-with-apicurio-and-red-hat-fuse%2F&amp;#38;linkname=Contract-First%20API%20Design%20with%20Apicurio%20and%20Red%20Hat%20Fuse%2FCamel" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F12%2Fcontract-first-api-design-with-apicurio-and-red-hat-fuse%2F&amp;#38;linkname=Contract-First%20API%20Design%20with%20Apicurio%20and%20Red%20Hat%20Fuse%2FCamel" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F12%2Fcontract-first-api-design-with-apicurio-and-red-hat-fuse%2F&amp;#38;title=Contract-First%20API%20Design%20with%20Apicurio%20and%20Red%20Hat%20Fuse%2FCamel" data-a2a-url="https://developers.redhat.com/blog/2018/07/12/contract-first-api-design-with-apicurio-and-red-hat-fuse/" data-a2a-title="Contract-First API Design with Apicurio and Red Hat Fuse/Camel"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/07/12/contract-first-api-design-with-apicurio-and-red-hat-fuse/"&gt;Contract-First API Design with Apicurio and Red Hat Fuse/Camel&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/C5nm9tnzf08" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This is part one of my two-article series that demonstrates how to implement contract-first API design using Apicurio and Red Hat Fuse.  It covers how to create an OpenAPI standard document as the contract between API providers and consumers using Apicurio Studio. It also shows how to quickly create mock tests using Red Hat Fuse which is [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/07/12/contract-first-api-design-with-apicurio-and-red-hat-fuse/"&gt;Contract-First API Design with Apicurio and Red Hat Fuse/Camel&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/07/12/contract-first-api-design-with-apicurio-and-red-hat-fuse/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">505057</post-id><dc:creator>Christina Lin</dc:creator><dc:date>2018-07-12T16:00:52Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/07/12/contract-first-api-design-with-apicurio-and-red-hat-fuse/</feedburner:origLink></entry></feed>
